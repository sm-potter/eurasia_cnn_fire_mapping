{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaaec0c-5fe1-421d-8d97-2254c38d5c72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLA_FLAGS: None\n",
      "       6      7      8\n",
      "0   21.0  -68.0   -9.0\n",
      "1  974.0  522.0  686.0\n",
      "101169\n",
      "25036\n",
      "17218\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Read in packages\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "#os.environ['LD_LIBRARY_PATH'] = '/home/spotter5/.conda/envs/deeplearning3/lib:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "# os.environ['CUDA_HOME'] = '/home/spotter5/.conda/envs/deeplearning/lib'\n",
    "#os.environ['NVVMIR_LIBRARY_DIR'] = '/home/spotter5/.conda/envs/deeplearning3/lib'\n",
    "# os.environ['NVVMIR_LIBRARY_DIR'] = '--xla_gpu_cuda_data_dir=/home/spotter5/.conda/envs/deeplearning/lib/python3.8/site-packages/jaxlib/cuda/nvvmb'\n",
    "\n",
    "# os.environ[\"XLA_FLAGS\"]=\"-–xla_gpu_cuda_data_dir=/home/spotter5/.conda/envs/deeplearning/lib\"\n",
    "# os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/home/spotter5/.conda/envs/deeplearning/lib\"\n",
    "# os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/home/spotter5/.conda/envs/deeplearning/nvvm/libdevice\"\n",
    "# os.environ[\"TF_XLA_FLAGS\"]=\"-–xla_gpu_cuda_data_dir=/home/spotter5/.conda/envs/deeplearning/lib\"\n",
    "\n",
    "# os.environ['XLA_FLAGS']='--xla_gpu_cuda_data_dir=/home/spotter5/.conda/envs/deeplearning/lib/python3.8/site-packages/jaxlib/cuda/nvvm'\n",
    "\n",
    "print(\"XLA_FLAGS:\", os.getenv(\"XLA_FLAGS\"))\n",
    "\n",
    "# if 'CONDA_PREFIX' in os.environ:\n",
    "#     os.environ['XLA_FLAGS'] = f'--xla_gpu_cuda_data_dir={os.environ[\"CONDA_PREFIX\"]}/lib'\n",
    "# else:\n",
    "#     print(\"CONDA_PREFIX not set. Are you running this script within an active Conda environment?\")\n",
    "\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "import os\n",
    "import segmentation_models as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import concatenate, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Input, AvgPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_unet_collection import models\n",
    "import geopandas as gpd\n",
    "# import tensorflow_addons as tfa\n",
    "import logging\n",
    "import time\n",
    "\n",
    "fold = 0\n",
    "# Record the start tim\n",
    "start_time = time.time()\n",
    "\n",
    "# gpu_devices = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices:\n",
    "#     tensorflow.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gpu_info = get_ipython().getoutput('nvidia-smi')\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#     print('Not connected to a GPU')\n",
    "# else:\n",
    "#     print(gpu_info)\n",
    "\n",
    "\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop = True)\n",
    "\n",
    "min_max = min_max[['6', '7', '8']]\n",
    "\n",
    "print(min_max)\n",
    "#functin to standardize all bands at once\n",
    "\n",
    "\n",
    "#function to standardize\n",
    "def normalize_meanstd(a, axis=None): \n",
    "    # axis param denotes axes along which mean & std reductions are to be performed\n",
    "    mean = np.mean(a, axis=axis, keepdims=True)\n",
    "    std = np.sqrt(((a - mean)**2).mean(axis=axis, keepdims=True))\n",
    "    return (a - mean) / std\n",
    "\n",
    "#function to normalize\n",
    "def normalize(a, axis=None): \n",
    "    # axis param denotes axes along which mean & std reductions are to be performed\n",
    "    minv = np.min(a, axis=axis, keepdims=True)\n",
    "    maxv = np.max(a, axis=axis, keepdims=True)\n",
    "    return (a - minv) / (maxv - minv)\n",
    "\n",
    "\n",
    "#function to get files from storage bucket\n",
    "def get_files(bucket_path):\n",
    "\n",
    "\t\"\"\"argument is the path to where the numpy\n",
    "\tsave files are located, return a list of filenames\n",
    "\t\"\"\"\n",
    "\tall = []\n",
    "\n",
    "\t#list of files\n",
    "\tfiles = os.listdir(bucket_path)\n",
    "\n",
    "\t#get list of filenames we will use, notte I remove images that don't have a target due to clouds\n",
    "\tfile_names = []\n",
    "\tfor f in files:\n",
    "\n",
    "\t\tif f.endswith('.npy'):\n",
    "\n",
    "\n",
    "\t\t\tall.append(os.path.join(bucket_path, f))\n",
    "\treturn(all)\n",
    "\n",
    "\n",
    "#get all the pathways\n",
    "training_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/train_fold_{fold}.csv')['ID'].tolist()\n",
    "validation_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/val_fold_{fold}.csv')['ID'].tolist()\n",
    "\n",
    "# training_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_ndsi_composites_training_files.csv')['Files'].tolist()\n",
    "# validation_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_ndsi_composites_validation_files.csv')['Files'].tolist()\n",
    "# testing_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_ndsi_composites_testing_files.csv')['Files'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "#now I need to get the chunked files which match the fire ids to make new training, validation and testing times\n",
    "#path to the chunked files\n",
    "chunked =  os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_ndsi_composites_subs_0_128')\n",
    "\n",
    "def filter_chunked(in_names, chunked):\n",
    "    \"\"\"\n",
    "    Filters items in the 'chunked' list based on whether the specified part of\n",
    "    each item (extracted by splitting the item's string) is in 'training_names'.\n",
    "\n",
    "    Parameters:\n",
    "    - training_names: List of integers to filter against.\n",
    "    - chunked: List of strings, where each string is a filename that contains numbers.\n",
    "\n",
    "    Returns:\n",
    "    - List of strings from 'chunked' that match the filtering criteria.\n",
    "    \"\"\"\n",
    "    # Filter the 'chunked' list\n",
    "    filtered_chunked = [\n",
    "        name for name in chunked \n",
    "        if int(name.split('_')[-1].split('.')[0]) in in_names\n",
    "    ]\n",
    "    \n",
    "    filtered_chunked = ['/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_ndsi_composites_subs_0_128/' + i for i in filtered_chunked]\n",
    "    return filtered_chunked\n",
    "\n",
    "training_names = filter_chunked(training_names, chunked)\n",
    "validation_names = filter_chunked(validation_names, chunked)\n",
    "testing_names = filter_chunked(testing_names, chunked)\n",
    "\n",
    "# training_names = training_names[:50]\n",
    "# validation_names = validation_names[:50]\n",
    "# testing_names = testing_names[:50]\n",
    "\n",
    "print(len(training_names))\n",
    "print(len(validation_names))\n",
    "print(len(testing_names))\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# # from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# #function to normalize within range\n",
    "# def normalize(start, end, arr):\n",
    "#     width = end - start\n",
    "#     res = (arr - np.nanmin(arr))/(np.nanmax(arr)- np.nanmin(arr)) * width + start\n",
    "\n",
    "# #     res = (arr - arr.min())/(arr.max() - arr.min()) * width + start\n",
    "#     return res\n",
    "\n",
    "# class img_gen(tensorflow.keras.utils.Sequence):\n",
    "\n",
    "#     \"\"\"Helper to iterate over the data (as Numpy arrays).\n",
    "#     Inputs are batch size, the image size, the input paths (x) and target paths (y)\n",
    "#     \"\"\"\n",
    "\n",
    "#     #will need pre defined variables batch_size, img_size, input_img_paths and target_img_paths\n",
    "#     def __init__(self, batch_size, img_size, input_img_paths):\n",
    "# \t    self.batch_size = batch_size\n",
    "# \t    self.img_size = img_size\n",
    "# \t    self.input_img_paths = input_img_paths\n",
    "# \t    self.target_img_paths = input_img_paths\n",
    "\n",
    "#     #number of batches the generator is supposed to produceis the length of the paths divided by the batch siize\n",
    "#     def __len__(self):\n",
    "# \t    return len(self.input_img_paths) // self.batch_size\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "#         \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "#         i = idx * self.batch_size\n",
    "#         batch_img_paths = self.input_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (x)\n",
    "#         batch_target_img_paths = self.target_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (y)\n",
    "\t\t\n",
    "#         x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\") #create matrix of zeros which will have the dimension height, wideth, n_bands), 8 is the n_bands\n",
    "        \n",
    "  \n",
    "#          #start populating x by enumerating over the input img paths\n",
    "#         for j, path in enumerate(batch_img_paths):\n",
    "\n",
    "#             #load image\n",
    "#             img =  np.round(np.load(path), 3)[:, :, :-1]\n",
    "\n",
    "#             # img = img * 1000\n",
    "#             img = img.astype(float)\n",
    "#             img = np.round(img, 3)\n",
    "#             img[img == 0] = -999\n",
    "\n",
    "#             img[np.isnan(img)] = -999\n",
    "\n",
    "\n",
    "#             img[img == -999] = np.nan\n",
    "\n",
    "#             in_shape = img.shape\n",
    "            \n",
    "#             #turn to dataframe to normalize\n",
    "#             img = img.reshape(img.shape[0] * img.shape[1], img.shape[2])\n",
    "\t\t\t\n",
    "#             img = pd.DataFrame(img)\n",
    "\t\t\t\n",
    "#             img.columns = min_max.columns\n",
    "\t\t\t\n",
    "#             img = pd.concat([min_max, img]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "#             #normalize 0 to 1\n",
    "#             img = pd.DataFrame(scaler.fit_transform(img))\n",
    "\t\t\t\n",
    "#             img = img.iloc[2:]\n",
    "# #\n",
    "# #             img = img.values.reshape(in_shape)\n",
    "#             img = img.values.reshape(in_shape)\n",
    "\n",
    "# #             replace nan with -1\n",
    "#             img[np.isnan(img)] = -1\n",
    "\n",
    "# #apply standardization\n",
    "# # img = normalize(img, axis=(0,1))\n",
    "\n",
    "#             img = np.round(img, 3)\n",
    "#             #populate x\n",
    "#             x[j] = img#[:, :, 4:] index number is not included, \n",
    "\n",
    "\n",
    "#         #do tthe same thing for y\n",
    "#         y = np.zeros((self.batch_size,) + self.img_size, dtype=\"uint8\")\n",
    "\n",
    "#         for j, path in enumerate(batch_target_img_paths):\n",
    "\n",
    "#             #load image\n",
    "#             img =  np.round(np.load(path), 3)[:, :, -1]\n",
    "\n",
    "#             img = img.astype(int)\n",
    "\n",
    "#             img[img < 0] = 0\n",
    "#             img[img >1] = 0\n",
    "#             img[~np.isin(img, [0,1])] = 0\n",
    "\n",
    "#             img[np.isnan(img)] = 0\n",
    "#             img = img.astype(int)\n",
    "\n",
    "#             # img =  tf.keras.utils.to_categorical(img, num_classes = 2)\n",
    "#             # y[j] = np.expand_dims(img, 2) \n",
    "#             y[j] = img\n",
    "  \n",
    "       \n",
    "#     #Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "#     # y[j] -= 1\n",
    "\n",
    "#         return x, y\n",
    "\n",
    "\n",
    "# # Read in the images based on the generator\n",
    "\n",
    "# # In[24]:\n",
    "\n",
    "\n",
    "# #Initialize GPUS with tensorflow\n",
    "\n",
    "\n",
    "# # In[2]:\n",
    "\n",
    "\n",
    "# gpu_devices = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices:\n",
    "#     tensorflow.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # gpu_info = get_ipython().getoutput('nvidia-smi')\n",
    "# # gpu_info = '\\n'.join(gpu_info)\n",
    "# # if gpu_info.find('failed') >= 0:\n",
    "# #     print('Not connected to a GPU')\n",
    "# # else:\n",
    "# #     print(gpu_info)\n",
    "    \n",
    "# # # watch -n0.5 nvidia-smi\n",
    "\n",
    "# # from tensorflow.python.client import device_lib\n",
    "# # devices = device_lib.list_local_devices()\n",
    "\n",
    "\n",
    "# #batch size and img size\n",
    "# #15 before\n",
    "# BATCH_SIZE = 45\n",
    "# GPUS = [\"GPU:0\", \"GPU:1\", \"GPU:2\", \"GPU:3\"]\n",
    "# strategy = tensorflow.distribute.MirroredStrategy() #can add GPUS here to select specific ones\n",
    "# print('Number of devices: %d' % strategy.num_replicas_in_sync) \n",
    "\n",
    "# batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "\n",
    "# #image size\n",
    "# img_size = (128, 128)\n",
    "# # img_size = (128, 128)\n",
    "\n",
    "# #number of classes to predict\n",
    "# num_classes = 1\n",
    "\n",
    "# #get images\n",
    "# train_gen = img_gen(batch_size, img_size, training_names)\n",
    "# val_gen = img_gen(batch_size, img_size, validation_names)\n",
    "# test_gen = img_gen(batch_size, img_size, testing_names)\n",
    "# #\n",
    "\n",
    "# # Free up RAM in case the model definition cells were run multiple times\n",
    "# # tensorflow.keras.backend.clear_session()\n",
    "\n",
    "# LR = 1e-3\n",
    "# optimizer = tensorflow.keras.optimizers.Adam(learning_rate = LR) #this is 1e-3, default or 'rmsprop'\n",
    "\n",
    "    \n",
    "# loss= tensorflow.keras.losses.BinaryFocalCrossentropy(\n",
    "#     from_logits=False,\n",
    "#     gamma = 2.0,\n",
    "#     alpha = 0.25)\n",
    "\n",
    "# # f.keras.losses.BinaryFocalCrossentropy(gamma=2.0, alpha=0.25)\n",
    "# # loss = tensorflow.keras.losses.BinaryFocalCrossentropy(\n",
    "# #     apply_class_balancing=False,\n",
    "# #     alpha=0.25,\n",
    "# #     gamma=2.0,\n",
    "# #     from_logits=False,\n",
    "# #     label_smoothing=0.0,\n",
    "# #     axis=-1,\n",
    "# #     reduction=losses_utils.ReductionV2.AUTO,\n",
    "# #     name='binary_focal_crossentropy'\n",
    "# # )\n",
    "\n",
    "\n",
    "# callbacks = [tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_{fold}\",\n",
    "# #     verbose=1,\n",
    "#     save_weights_only=False,\n",
    "#     save_best_only=True,\n",
    "#         monitor='val_unet_output_final_activation_iou_score',\n",
    "#     mode = 'max'),\n",
    "#     tensorflow.keras.callbacks.EarlyStopping(monitor='val_unet_output_final_activation_iou_score', mode = 'max',  patience=20),\n",
    "#     tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_unet_output_final_activation_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)]\n",
    "    \n",
    "# # tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', mode = 'min', patience = 10, min_delta=0.001, min_LR = LR/25, verbose = 1)\n",
    "\n",
    "# # Open a strategy scope.\n",
    "# with strategy.scope():\n",
    "    \n",
    "#     #one [16,32,64,128]\n",
    "#     #two [16,32,64,128,256]\n",
    "#     #three [32,64,128,256]\n",
    "#     #four [32,64,128,256,512]\n",
    "#     #five [16,32,64,128,256,512,1024]\n",
    "\n",
    "\n",
    "#     model_unet_from_scratch = models.unet_plus_2d((None, None, 3), filter_num= [16,32,64,128], #make smaller64, 128, 256, 512,[16, 32, 64, 128]\n",
    "#                        n_labels=num_classes, \n",
    "#                        stack_num_down=2, stack_num_up=2, \n",
    "#                        activation='ReLU', \n",
    "#                        output_activation='Sigmoid', \n",
    "#                        batch_norm=True, pool=False, unpool=False, \n",
    "#                        backbone='EfficientNetB7', weights=None, \n",
    "#                        freeze_backbone=False, freeze_batch_norm=False, \n",
    "#                        deep_supervision = True,\n",
    "#                        name='unet')\n",
    "\n",
    "#     # model_unet_from_scratch = models.unet_3plus_2d((None, None, 1), n_labels=num_classes, filter_num_down=[16,32,64,128], \n",
    "#     #                          filter_num_skip='auto', filter_num_aggregate='auto', \n",
    "#     #                         backbone='EfficientNetB7', weights=None, \n",
    "#     #                          freeze_backbone=False,\n",
    "#     #                          stack_num_down=2, stack_num_up=1, activation='ReLU', output_activation='Sigmoid',\n",
    "#     #                          batch_norm=True, pool='max', unpool=False, deep_supervision=True, name='unet')\n",
    "\t\n",
    "# #     model.set_weights(listOfNumpyArrays)\n",
    "#     model_unet_from_scratch.compile(loss='binary_crossentropy',\n",
    "#                                     # loss = loss,\n",
    "#                                     optimizer='adam',\n",
    "#                                     metrics=[sm.metrics.Precision(threshold=0.5),\n",
    "#                                       sm.metrics.Recall(threshold=0.5),\n",
    "#                                       sm.metrics.FScore(threshold=0.5), \n",
    "#                                       sm.metrics.IOUScore(threshold=0.5),\n",
    "#                                       'accuracy'])\n",
    "\n",
    "# #fit the model\n",
    "# history = model_unet_from_scratch.fit(\n",
    "#     train_gen,\n",
    "#     epochs=50,\n",
    "#     callbacks = callbacks,\n",
    "#     validation_data=val_gen,\n",
    "#     verbose = 0) \n",
    "\n",
    "# # model_unet_from_scratch.save(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_079_128.h5\")\n",
    "# model_unet_from_scratch.save(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_{fold}.tf\")\n",
    "\n",
    "\n",
    "# history_dict = history.history\n",
    "\n",
    "# #save output\n",
    "# # result = pd.DataFrame({'Precision': history_dict[\"precision\"],\n",
    "# #                        'Val_Precision': history_dict['val_precision'],\n",
    "# #                        'Recall': history_dict[\"recall\"],\n",
    "# #                        'Val_Recall': history_dict['recall'],\n",
    "# #                        'F1': history_dict[\"f1-score\"],\n",
    "# #                        'Val_F1': history_dict['val_f1-score'],\n",
    "# #                        'IOU': history_dict[\"iou_score\"],\n",
    "# #                        'Val_IOU': history_dict['val_iou_score'],\n",
    "# #                        'Loss': history_dict['loss'],\n",
    "# #                        'Val_Loss': history_dict['val_loss']})\n",
    "\n",
    "# result = pd.DataFrame({'Precision': history_dict[\"unet_output_final_activation_precision\"],\n",
    "#                        'Val_Precision': history_dict['val_unet_output_final_activation_precision'],\n",
    "#                        'Recall': history_dict[\"unet_output_final_activation_recall\"],\n",
    "#                        'Val_Recall': history_dict['val_unet_output_final_activation_recall'],\n",
    "#                        'F1': history_dict[\"unet_output_final_activation_f1-score\"],\n",
    "#                        'Val_F1': history_dict['val_unet_output_final_activation_f1-score'],\n",
    "#                        'IOU': history_dict[\"unet_output_final_activation_iou_score\"],\n",
    "#                        'Val_IOU': history_dict['val_unet_output_final_activation_iou_score'],\n",
    "#                        'Loss': history_dict['unet_output_final_activation_loss'],\n",
    "#                        'Val_Loss': history_dict['val_unet_output_final_activation_loss'],\n",
    "#                       'Accuracy': history_dict['unet_output_final_activation_accuracy'],\n",
    "#                        'Val_Accuracy': history_dict['val_unet_output_final_activation_accuracy']})\n",
    "\n",
    "\n",
    "# result.to_csv(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/russia_good_no_regularize_ndsi_{fold}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# # Record the end time\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Calculate the time difference in seconds\n",
    "# time_difference_seconds = end_time - start_time\n",
    "\n",
    "# # Convert seconds to hours\n",
    "# time_difference_hours = time_difference_seconds / 3600  # 1 hour = 3600 seconds\n",
    "\n",
    "# print(f\"Time taken: {time_difference_hours:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1834b3-2c94-49a6-9157-c45b4bf0dcbc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176f642-0699-4f95-9a92-b9051226b247",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
