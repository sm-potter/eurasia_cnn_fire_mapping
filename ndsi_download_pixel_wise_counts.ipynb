{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3ac0b5-4fb2-47ed-beb2-95dffca63bf6",
   "metadata": {},
   "source": [
    "This script will attempt to download the image composites by using per pixel NDSI info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55978084-7455-45d7-b116-8a040bc65c92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_pre_post' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 199\u001b[0m\n\u001b[1;32m    196\u001b[0m post_end \u001b[38;5;241m=\u001b[39m pre_end\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Apply the function to get the pre_fire and post_fire images\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m all_imagery \u001b[38;5;241m=\u001b[39m \u001b[43mget_pre_post\u001b[49m(pre_start, pre_end, post_start, post_end, final_buffer)\n\u001b[1;32m    201\u001b[0m pre_input \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mImageCollection(all_imagery[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmap(filter_by_snow_days)\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[1;32m    202\u001b[0m post_input \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mImageCollection(all_imagery[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mmap(filter_by_snow_days)\u001b[38;5;241m.\u001b[39mmedian()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_pre_post' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import ee\n",
    "import numpy as np\n",
    "from geeml.extract import extractor\n",
    "import pandas as pd\n",
    "import random\n",
    "# import geemap\n",
    "# Authenticate GEE\n",
    "# ee.Authenticate()\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "\n",
    "service_account = 'gee-serdp-upload@appspot.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "ee.Initialize(credentials)\n",
    "# Initialize GEE with high-volume end-point\n",
    "# ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "ee.Initialize()\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import geemap\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from google.cloud import client\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "storage_client = storage.Client.from_service_account_json(\"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "storage_client = storage.Client()\n",
    "# bucket_name = 'smp-scratch/mtbs_1985'\n",
    "bucket_name = 'smp-scratch'\n",
    "\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "\n",
    "# Import assetts of interest\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "geometry = ee.FeatureCollection('users/spotter/fire_cnn/raw/eurasia') #area of interest\n",
    "mod1 = ee.ImageCollection(\"MODIS/061/MOD10A1\") #active fire\n",
    "mod2 = ee.ImageCollection(\"MODIS/061/MYD10A1\") #active fire\n",
    "fire_cci = ee.ImageCollection(\"ESA/CCI/FireCCI/5_1\") #active fire\n",
    "mod_burn = ee.ImageCollection(\"MODIS/061/MCD64A1\") #mcd64a1\n",
    "snow = ee.ImageCollection('MODIS/006/MOD10A1') #modis snow cover\n",
    "# Load the MODIS water mask image and invert it.\n",
    "water_mask = ee.Image('MODIS/MOD44W/MOD44W_005_2000_02_24').select('water_mask').Not()\n",
    "\n",
    "\n",
    "sent_2A = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") #sentinel 2\n",
    "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY') #cloud masking for sentinel\n",
    "# s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY') #cloud masking for sentinel\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_1985\") #nbac_fire_polygons, this can be any polygon shapefile, final version would be nbac and mtbs\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/ann_w_id\") #anna polygons \n",
    "lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/anna_w_id_sampled\") #anna polygons \n",
    "\n",
    "# Cloud masking Sentinel 2\n",
    "MAX_CLOUD_PROBABILITY = 50\n",
    "\n",
    "def sent_maskcloud(image):\n",
    "    image = image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'])  # Rename bands to match Landsat\n",
    "    clouds = ee.Image(image.get('cloud_mask')).select('probability')\n",
    "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
    "    image = image.updateMask(isNotCloud)\n",
    "\n",
    "    image1 = image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4']).reproject(crs=image.projection().crs(), scale=30)\n",
    "    image2 = image.select(['SR_B5', 'SR_B7']).reproject(crs=image.projection().crs(), scale=30)\n",
    "    return image1.addBands(image2)\n",
    "\n",
    "# Join Sentinel 2 SR with cloud probability dataset to add cloud mask\n",
    "s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
    "    primary=sent_2A,\n",
    "    secondary=s2Clouds,\n",
    "    condition=ee.Filter.equals(leftField='system:index', rightField='system:index')\n",
    ")\n",
    "\n",
    "# Apply cloud masking\n",
    "sent_2A = ee.ImageCollection(s2SrWithCloudMask).map(sent_maskcloud)\n",
    "\n",
    "# Snow quality masking\n",
    "def mask_quality_snow(image):\n",
    "    qa = image.select('NDSI_Snow_Cover_Basic_QA')\n",
    "    quality_mask = qa.bitwiseAnd(3).eq(0)\n",
    "    return image.updateMask(quality_mask)\n",
    "\n",
    "snow = snow.map(mask_quality_snow).select('NDSI_Snow_Cover')\n",
    "\n",
    "# Add date bands\n",
    "def add_date_bands(img):\n",
    "    global start_date, start_year_var\n",
    "    date = img.date()\n",
    "    cal_doy = date.getRelative('day', 'year')\n",
    "    rel_doy = date.difference(start_date, 'day')\n",
    "    millis = date.millis()\n",
    "    date_bands = ee.Image.constant([cal_doy, rel_doy, millis, start_year_var]).rename(['calDoy', 'relDoy', 'millis', 'year'])\n",
    "    return img.addBands(date_bands).cast({'calDoy': 'int', 'relDoy': 'int', 'millis': 'long', 'year': 'int'}).set('millis', millis)\n",
    "\n",
    "# Process year for last day of snow in spring\n",
    "def process_year(year):\n",
    "    global start_date, start_year_var\n",
    "    start_year_var = year\n",
    "    start_date = ee.Date.fromYMD(year, 1, 1)\n",
    "    end_date = ee.Date.fromYMD(year, 7, 1)\n",
    "    \n",
    "    year_col = snow.filterDate(start_date, end_date)\n",
    "    \n",
    "    no_snow_img = year_col.map(add_date_bands).sort('millis').reduce(ee.Reducer.min(5)).rename(['snowCover', 'calDoy', 'relDoy', 'millis', 'year']).set('year', year)\n",
    "    \n",
    "    return no_snow_img.updateMask(no_snow_img.select('snowCover').eq(0)).select('calDoy').rename('last_spring_snow_day')\n",
    "\n",
    "# Process year for first day of snow in fall\n",
    "def process_year_fall(year):\n",
    "    global start_date, start_year_var\n",
    "    start_year_var = year\n",
    "    start_date = ee.Date.fromYMD(year, 8, 31)\n",
    "    end_date = ee.Date.fromYMD(year, 12, 31)\n",
    "    \n",
    "    year_col = snow.filterDate(start_date, end_date)\n",
    "    \n",
    "    no_snow_img = year_col.map(add_date_bands).sort('millis', False).reduce(ee.Reducer.min(5)).rename(['snowCover', 'calDoy', 'relDoy', 'millis', 'year']).set('year', year)\n",
    "    \n",
    "    return no_snow_img.updateMask(no_snow_img.select('snowCover').eq(0)).select('calDoy').rename('first_fall_snow_day')\n",
    "\n",
    "# Create a zero image for cases with no data\n",
    "def create_zero_image(region):\n",
    "    zero_pre = ee.Image.constant(0).rename('pre').toShort()\n",
    "    zero_post = ee.Image.constant(0).rename('post').toShort()\n",
    "    zero_image = zero_pre.addBands(zero_post)\n",
    "    return zero_image.clip(region)\n",
    "\n",
    "# Main processing loop\n",
    "all_ids = ee.List(lfdb.distinct([\"ID\"]).aggregate_array(\"ID\")).getInfo()\n",
    "\n",
    "all_ids = [52, 3266]\n",
    "pre_months = ['-06-01']\n",
    "end_months = ['-08-31']\n",
    "\n",
    "all_months = dict(zip(pre_months, end_months))\n",
    "\n",
    "folder_name = 'ndsi_counts_pixel_wise'\n",
    "\n",
    "for i in all_ids:\n",
    "    fname = f\"{folder_name}/final_{i}\"\n",
    "    stats = storage.Blob(bucket=bucket, name=fname).exists(storage_client)\n",
    "    \n",
    "    if not stats:\n",
    "        sub_shape = lfdb.filter(ee.Filter.eq(\"ID\", i))\n",
    "        bbox = sub_shape.geometry().bounds()\n",
    "        all_rands = [0.00]\n",
    "        rand1 = random.sample(all_rands, 1)[0]\n",
    "        rand2 = random.sample(all_rands, 1)[0]\n",
    "        proj = ee.Projection(\"EPSG:4326\").translate(rand1, rand2)\n",
    "        final_buffer = ee.Geometry.Polygon(bbox.coordinates(), proj).transform(proj)\n",
    "        final_buffer2 = final_buffer.buffer(distance=5000).bounds()\n",
    "\n",
    "        this_year = ee.Number(sub_shape.aggregate_array('Year').get(0)).getInfo()\n",
    "        start_year = this_year - 1\n",
    "        end_year = this_year + 1\n",
    "\n",
    "        # Apply process_year and process_year_fall for the relevant years\n",
    "        start_year_snow = process_year(start_year).clip(final_buffer)\n",
    "        end_year_snow = process_year(end_year).clip(final_buffer)\n",
    "        start_year_snow_fall = process_year_fall(start_year).clip(final_buffer)\n",
    "        end_year_snow_fall = process_year_fall(end_year).clip(final_buffer)\n",
    "\n",
    "        # Compute the last spring snow day and first fall snow day for each pixel\n",
    "        last_spring_snow_day = ee.ImageCollection([start_year_snow, end_year_snow]).max()\n",
    "        first_fall_snow_day = ee.ImageCollection([start_year_snow_fall, end_year_snow_fall]).min()\n",
    "\n",
    "        # Shift the days to define the valid composite period\n",
    "        start_day = last_spring_snow_day.add(7)\n",
    "        end_day = first_fall_snow_day.subtract(7)\n",
    "\n",
    "        def filter_by_snow_days(img):\n",
    "            cal_doy = img.select('calDoy')\n",
    "            mask = cal_doy.gte(start_day).And(cal_doy.lte(end_day))\n",
    "            return img.updateMask(mask)\n",
    "\n",
    "        for m1, m2 in all_months.items():\n",
    "            pre_start = ee.Date.fromYMD(start_year, 6, 1)\n",
    "            pre_end = ee.Date.fromYMD(start_year, 8, 31)\n",
    "            post_start = pre_start.advance(2, 'year')\n",
    "            post_end = pre_end.advance(2, 'year')\n",
    "\n",
    "            # Apply the function to get the pre_fire and post_fire images\n",
    "            all_imagery = get_pre_post(pre_start, pre_end, post_start, post_end, final_buffer)\n",
    "\n",
    "            pre_input = ee.ImageCollection(all_imagery[0]).map(filter_by_snow_days).median()\n",
    "            post_input = ee.ImageCollection(all_imagery[1]).map(filter_by_snow_days).median()\n",
    "\n",
    "            raw_bands = pre_input.subtract(post_input).multiply(1000).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'], ['NBR', 'NDVI', 'NDII'])\n",
    "\n",
    "            raw_bands = raw_bands.clip(final_buffer)\n",
    "\n",
    "            combined_image = create_zero_image(final_buffer2) if len(all_imagery[0]) == 0 or len(all_imagery[1]) == 0 else raw_bands\n",
    "\n",
    "            task = ee.batch.Export.image.toCloudStorage(\n",
    "                image=combined_image.toShort(),\n",
    "                region=final_buffer2, \n",
    "                description=f\"{folder_name}/{m1}_{m2}_{i}\",\n",
    "                scale=30,\n",
    "                crs='EPSG:3413',\n",
    "                maxPixels=1e13,\n",
    "                bucket='smp-scratch',\n",
    "                fileNamePrefix=f\"{folder_name}/{m1}_{m2}_{i}\"\n",
    "            )\n",
    "            task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4780b8-a601-48b7-828f-6636ea277c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gee_ml]",
   "language": "python",
   "name": "conda-env-.conda-gee_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
