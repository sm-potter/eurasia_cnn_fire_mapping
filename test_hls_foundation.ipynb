{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a56d28-b6d0-4a79-9fc1-3322f0ef2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "custom_imports = dict(imports=[\"geospatial_fm\"])\n",
    "\n",
    "# base options\n",
    "dist_params = dict(backend=\"nccl\")\n",
    "log_level = \"INFO\"\n",
    "load_from = None\n",
    "resume_from = None\n",
    "cudnn_benchmark = True\n",
    "\n",
    "dataset_type = \"GeospatialDataset\"\n",
    "\n",
    "# TO BE DEFINED BY USER: data directory\n",
    "data_root = \"/explore/nobackup/people/spotter5/cnn_mapping/Russia/hls_test_divided\"\n",
    "\n",
    "num_frames = 1\n",
    "img_size = 224\n",
    "num_workers = 4\n",
    "samples_per_gpu = 4\n",
    "\n",
    "img_norm_cfg = dict(\n",
    "    means=[\n",
    "        0.033349706741586264,\n",
    "        0.05701185520536176,\n",
    "        0.05889748132001316,\n",
    "        0.2323245113436119,\n",
    "        0.1972854853760658,\n",
    "        0.11944914225186566,\n",
    "    ],\n",
    "    stds=[\n",
    "        0.02269135568823774,\n",
    "        0.026807560223070237,\n",
    "        0.04004109844362779,\n",
    "        0.07791732423672691,\n",
    "        0.08708738838140137,\n",
    "        0.07241979477437814,\n",
    "    ],\n",
    ")  # change the mean and std of all the bands\n",
    "\n",
    "bands = [0, 1, 2, 3, 4, 5]\n",
    "tile_size = 224\n",
    "orig_nsize = 512\n",
    "crop_size = (tile_size, tile_size)\n",
    "img_suffix = \"_merged.tif\"\n",
    "seg_map_suffix = \".mask.tif\"\n",
    "ignore_index = -1\n",
    "image_nodata = -9999\n",
    "image_nodata_replace = 0\n",
    "image_to_float32 = True\n",
    "\n",
    "# model\n",
    "# TO BE DEFINED BY USER: model path\n",
    "pretrained_weights_path = \"/home/spotter5/.conda/envs/pytorch/lib/python3.9/site-packages/hls-foundation-os/burn_scars_Prithvi_100M.pth\"\n",
    "num_layers = 12\n",
    "patch_size = 16\n",
    "embed_dim = 768\n",
    "num_heads = 12\n",
    "tubelet_size = 1\n",
    "output_embed_dim = num_frames * embed_dim\n",
    "max_intervals = 10000\n",
    "evaluation_interval = 1000\n",
    "\n",
    "# # TO BE DEFINED BY USER: model path\n",
    "experiment = \"test_1\"\n",
    "project_dir = \"/explore/nobackup/people/spotter5/cnn_mapping/Russia/hls_test_divided/hls_foundation_test\"\n",
    "work_dir = os.path.join(project_dir, experiment)\n",
    "os.makedirs(work_dir, exist_ok = True)\n",
    "save_path = work_dir\n",
    "\n",
    "save_path = work_dir\n",
    "train_pipeline = [\n",
    "    dict(type=\"LoadGeospatialImageFromFile\", to_float32=image_to_float32),\n",
    "    dict(type=\"LoadGeospatialAnnotations\", reduce_zero_label=False),\n",
    "    dict(type=\"BandsExtract\", bands=bands),\n",
    "    dict(type=\"RandomFlip\", prob=0.5),\n",
    "    dict(type=\"ToTensor\", keys=[\"img\", \"gt_semantic_seg\"]),\n",
    "    # to channels first\n",
    "    dict(type=\"TorchPermute\", keys=[\"img\"], order=(2, 0, 1)),\n",
    "    dict(type=\"TorchNormalize\", **img_norm_cfg),\n",
    "    dict(type=\"TorchRandomCrop\", crop_size=(tile_size, tile_size)),\n",
    "    dict(\n",
    "        type=\"Reshape\",\n",
    "        keys=[\"img\"],\n",
    "        new_shape=(len(bands), num_frames, tile_size, tile_size),\n",
    "    ),\n",
    "    dict(type=\"Reshape\", keys=[\"gt_semantic_seg\"], new_shape=(1, tile_size, tile_size)),\n",
    "    dict(type=\"CastTensor\", keys=[\"gt_semantic_seg\"], new_type=\"torch.LongTensor\"),\n",
    "    dict(type=\"Collect\", keys=[\"img\", \"gt_semantic_seg\"]),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type=\"LoadGeospatialImageFromFile\", to_float32=image_to_float32),\n",
    "    dict(type=\"BandsExtract\", bands=bands),\n",
    "    dict(type=\"ToTensor\", keys=[\"img\"]),\n",
    "    # to channels first\n",
    "    dict(type=\"TorchPermute\", keys=[\"img\"], order=(2, 0, 1)),\n",
    "    dict(type=\"TorchNormalize\", **img_norm_cfg),\n",
    "    dict(\n",
    "        type=\"Reshape\",\n",
    "        keys=[\"img\"],\n",
    "        new_shape=(len(bands), num_frames, -1, -1),\n",
    "        look_up=dict({\"2\": 1, \"3\": 2}),\n",
    "    ),\n",
    "    dict(type=\"CastTensor\", keys=[\"img\"], new_type=\"torch.FloatTensor\"),\n",
    "    dict(\n",
    "        type=\"CollectTestList\",\n",
    "        keys=[\"img\"],\n",
    "        meta_keys=[\n",
    "            \"img_info\",\n",
    "            \"seg_fields\",\n",
    "            \"img_prefix\",\n",
    "            \"seg_prefix\",\n",
    "            \"filename\",\n",
    "            \"ori_filename\",\n",
    "            \"img\",\n",
    "            \"img_shape\",\n",
    "            \"ori_shape\",\n",
    "            \"pad_shape\",\n",
    "            \"scale_factor\",\n",
    "            \"img_norm_cfg\",\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "CLASSES = (\"Unburnt land\", \"Burn scar\")\n",
    "\n",
    "data = dict(\n",
    "    samples_per_gpu=samples_per_gpu,\n",
    "    workers_per_gpu=num_workers,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        CLASSES=CLASSES,\n",
    "        data_root=data_root,\n",
    "        img_dir=\"training\",\n",
    "        ann_dir=\"training\",\n",
    "        img_suffix=img_suffix,\n",
    "        seg_map_suffix=seg_map_suffix,\n",
    "        pipeline=train_pipeline,\n",
    "        ignore_index=-1,\n",
    "    ),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        CLASSES=CLASSES,\n",
    "        data_root=data_root,\n",
    "        img_dir=\"validation\",\n",
    "        ann_dir=\"validation\",\n",
    "        img_suffix=img_suffix,\n",
    "        seg_map_suffix=seg_map_suffix,\n",
    "        pipeline=test_pipeline,\n",
    "        ignore_index=-1,\n",
    "    ),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        CLASSES=CLASSES,\n",
    "        data_root=data_root,\n",
    "        img_dir=\"validation\",\n",
    "        ann_dir=\"validation\",\n",
    "        img_suffix=img_suffix,\n",
    "        seg_map_suffix=seg_map_suffix,\n",
    "        pipeline=test_pipeline,\n",
    "        ignore_index=-1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "optimizer = dict(type=\"Adam\", lr=1.3e-05, betas=(0.9, 0.999))\n",
    "optimizer_config = dict(grad_clip=None)\n",
    "lr_config = dict(\n",
    "    policy=\"poly\",\n",
    "    warmup=\"linear\",\n",
    "    warmup_iters=1500,\n",
    "    warmup_ratio=1e-06,\n",
    "    power=1.0,\n",
    "    min_lr=0.0,\n",
    "    by_epoch=False,\n",
    ")\n",
    "log_config = dict(\n",
    "    interval=20,\n",
    "    hooks=[\n",
    "        dict(type=\"TextLoggerHook\", by_epoch=False),\n",
    "        dict(type=\"TensorboardLoggerHook\", by_epoch=False),\n",
    "    ],\n",
    ")\n",
    "checkpoint_config = dict(by_epoch=True, interval=10, out_dir=save_path)\n",
    "evaluation = dict(\n",
    "    interval=evaluation_interval,\n",
    "    metric=\"mIoU\",\n",
    "    pre_eval=True,\n",
    "    save_best=\"mIoU\",\n",
    "    by_epoch=False,\n",
    ")\n",
    "\n",
    "loss_func = dict(type=\"DiceLoss\", use_sigmoid=False, loss_weight=1, ignore_index=-1)\n",
    "\n",
    "runner = dict(type=\"IterBasedRunner\", max_iters=max_intervals)\n",
    "workflow = [(\"train\", 1)]\n",
    "norm_cfg = dict(type=\"BN\", requires_grad=True)\n",
    "model = dict(\n",
    "    type=\"TemporalEncoderDecoder\",\n",
    "    frozen_backbone=False,\n",
    "    backbone=dict(\n",
    "        type=\"TemporalViTEncoder\",\n",
    "        pretrained=pretrained_weights_path,\n",
    "        img_size=img_size,\n",
    "        patch_size=patch_size,\n",
    "        num_frames=num_frames,\n",
    "        tubelet_size=tubelet_size,\n",
    "        in_chans=len(bands),\n",
    "        embed_dim=embed_dim,\n",
    "        depth=12,\n",
    "        num_heads=num_heads,\n",
    "        mlp_ratio=4.0,\n",
    "        norm_pix_loss=False,\n",
    "    ),\n",
    "    neck=dict(\n",
    "        type=\"ConvTransformerTokensToEmbeddingNeck\",\n",
    "        embed_dim=embed_dim * num_frames,\n",
    "        output_embed_dim=output_embed_dim,\n",
    "        drop_cls_token=True,\n",
    "        Hp=14,\n",
    "        Wp=14,\n",
    "    ),\n",
    "    decode_head=dict(\n",
    "        num_classes=len(CLASSES),\n",
    "        in_channels=output_embed_dim,\n",
    "        type=\"FCNHead\",\n",
    "        in_index=-1,\n",
    "        channels=256,\n",
    "        num_convs=1,\n",
    "        concat_input=False,\n",
    "        dropout_ratio=0.1,\n",
    "        norm_cfg=dict(type=\"BN\", requires_grad=True),\n",
    "        align_corners=False,\n",
    "        loss_decode=loss_func,\n",
    "    ),\n",
    "    auxiliary_head=dict(\n",
    "        num_classes=len(CLASSES),\n",
    "        in_channels=output_embed_dim,\n",
    "        type=\"FCNHead\",\n",
    "        in_index=-1,\n",
    "        channels=256,\n",
    "        num_convs=2,\n",
    "        concat_input=False,\n",
    "        dropout_ratio=0.1,\n",
    "        norm_cfg=dict(type=\"BN\", requires_grad=True),\n",
    "        align_corners=False,\n",
    "        loss_decode=loss_func,\n",
    "    ),\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(\n",
    "        mode=\"slide\",\n",
    "        stride=(int(tile_size / 2), int(tile_size / 2)),\n",
    "        crop_size=(tile_size, tile_size),\n",
    "    ),\n",
    ")\n",
    "auto_resume = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747330d4-05ba-472a-96d5-dfefa1a1f437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ilab-pytorch]",
   "language": "python",
   "name": "conda-env-ilab-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
