{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e64633b-961c-46f4-ade9-24384ff8bb0e",
   "metadata": {},
   "source": [
    "Read in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00387a58-86f6-4282-bf6b-23d2bef9e01a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import glob\n",
    "import random\n",
    "import geopandas as gpd\n",
    "from sklearn.utils import shuffle\n",
    "from MightyMosaic import MightyMosaic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a36b9-8b64-4ac7-8556-57d38ad118b0",
   "metadata": {},
   "source": [
    "First take the input tif files and chunk them to sizes of 128x128 for the neural network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0dd24e-f417-4f53-9bf3-4a46103d1a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"arguments are path to .tif files to be chunked, out_path to save files, chunk size, and if desired a threshold\"\"\"\n",
    "\n",
    "#check if all 0\n",
    "def is_matrix_all_zeros(matrix):\n",
    "    # Convert the matrix to a NumPy array\n",
    "    np_matrix = np.array(matrix)\n",
    "\n",
    "    # Check if all elements in the array are zeros\n",
    "    return np.all(np_matrix == 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#mtbs path \n",
    "mtbs_path =  '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/mtbs_no_data'\n",
    "\n",
    "#path to original shapefile which I need to retrieve the year of burn\n",
    "shapes = gpd.read_file('/explore/nobackup/people/spotter5/cnn_mapping/raw_files/ak_mtbs_1985.shp')\n",
    "shapes['Year'] = shapes['Year'].astype(int)\n",
    "            \n",
    "#in_path to tif files\n",
    "in_path = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_proj_mtbs'\n",
    "\n",
    "#out_path which will be manipulated based on parameters below\n",
    "out_path = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/l8_sent_collection2_proj_mtbs_unburned'\n",
    "\n",
    "#right now everything is set to use 0 dnbr threshold\n",
    "size = 128\n",
    "threshold = True\n",
    "\n",
    "if threshold == True:\n",
    "\n",
    "    out_path = out_path + '_subs_0_' + str(size)\n",
    "    if not os.path.isdir(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "if threshold == False:\n",
    "\n",
    "    out_path = out_path + '_subs_' + str(size)\n",
    "    if not os.path.isdir(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "files = os.listdir(in_path)\n",
    "\n",
    "#loop through files\n",
    "for f in files:\n",
    "\n",
    "    if f.endswith('.tif'):\n",
    "        \n",
    "         #in file\n",
    "        try:\n",
    "\n",
    "            \n",
    "            \n",
    "            #file name\n",
    "            f2 = f.replace('median_', '')\n",
    "\n",
    "            #ID of file\n",
    "            f_id = int(f2.replace('.tif', ''))\n",
    "        \n",
    "      \n",
    "       \n",
    "            #read in file\n",
    "            in_mat = rioxarray.open_rasterio(os.path.join(in_path, f))\n",
    "            \n",
    "        \n",
    "            #get sub shape\n",
    "            sub_shape= shapes[shapes['ID'] == f_id]\n",
    "\n",
    "            #get fire year of id\n",
    "            fire_year = str(sub_shape['Year'].unique()[0])\n",
    "\n",
    "            #read in mtbs\n",
    "            in_mtbs = rioxarray.open_rasterio(os.path.join(mtbs_path, 'mtbs_AK_' + fire_year + '.tif'))\n",
    "\n",
    "            #project it to in_mat\n",
    "            in_mtbs = in_mtbs.rio.reproject_match(in_mat)\n",
    "\n",
    "            #now turn in mat to numpy, and in mtbs to numpy\n",
    "            in_mat = in_mat.to_numpy().astype(float)\n",
    "\n",
    "\n",
    "            #convert to band last\n",
    "            in_mat = np.moveaxis(in_mat, 0, 2) \n",
    "            \n",
    "            #get dnbr\n",
    "            t = in_mat[:, :, 6]\n",
    "            \n",
    "             #check if all 0\n",
    "            result = is_matrix_all_zeros(t)\n",
    "            \n",
    "            #if it is not all 0s keep data\n",
    "            if result == False:\n",
    "\n",
    "                # in_mtbs.plot()\n",
    "                in_mtbs = in_mtbs.to_numpy().astype(float)\n",
    "\n",
    "                in_mtbs[in_mtbs == 255] = np.nan\n",
    "\n",
    "                y = in_mat[:, :, -1] \n",
    "\n",
    "                y[np.isnan(in_mtbs[0, :, :])] = np.nan\n",
    "\n",
    "                #replace in mat last band with y\n",
    "                in_mat[:, :, -1] = y\n",
    "\n",
    "                #mosaic\n",
    "                mosaic = MightyMosaic.from_array(in_mat, (size,size), overlap_factor=1) \n",
    "\n",
    "                #take off last dimensions of mosaic which give edge effects as they are filled with no data\n",
    "                mosaic = mosaic[:-1, :-1, :, :, :]\n",
    "\n",
    "\n",
    "                #first two dimensions are number of chunks, 3 and 4 are size (256, 266) and last is nbands\n",
    "                for i in range(mosaic.shape[0]):\n",
    "\n",
    "                    for j in range(mosaic.shape[1]):\n",
    "\n",
    "                        fname = os.path.join(str(i) + '_' +  str(j)+ '_' + f2.replace('.tif', '.npy'))\n",
    "                        out_name = os.path.join(out_path, fname)\n",
    "\n",
    "                        if os.path.exists(out_name) == False:\n",
    "\n",
    "                            in_mat3 = mosaic[i, j, :, :, :-1]\n",
    "\n",
    "                            target = mosaic[i, j, :, :, 9]\n",
    "\n",
    "                            #turn nan to -999\n",
    "                            in_mat[np.isnan(in_mat)] = -999\n",
    "\n",
    "\n",
    "                            # target = target.astype('int')\n",
    "\n",
    "                            target[target <0 ] = 0\n",
    "                            target[target >1 ] = 0\n",
    "\n",
    "                            #\n",
    "                            target[~np.isin(target, [0,1])] = 0\n",
    "\n",
    "                            #turn nan to 0\n",
    "                            target[np.isnan(target)] = 0\n",
    "\n",
    "                            #if the target is all 0 don't train on it\n",
    "                            # if np.all(target == 0) == False:\n",
    "\n",
    "                            #now get dnbr which is the 6th band\n",
    "                            dnbr = in_mat3[:, :, 6]\n",
    "\n",
    "                            result1 = is_matrix_all_zeros(dnbr)\n",
    "\n",
    "                            if result1 == False:\n",
    "\n",
    "\n",
    "                                #if threshold apply dnbr threshold\n",
    "                                target[dnbr < 0] = 0\n",
    "\n",
    "                                e = np.dstack([in_mat3, target])\n",
    "\n",
    "                                np.save(out_name, e)\n",
    "\n",
    "                                print(f)\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a470ca-1c1b-4006-81a2-fa728a3fea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8da9a9-7042-4100-95fb-288c85f30fba",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now take those files and save a csv with file names for the 80/10/10 training, validation, testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3404b1b-4457-4437-98be-4837efe428fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37352\n",
      "(29882, 1)\n",
      "(3735, 1)\n",
      "(3735, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
    "#list of files\n",
    "# file_names = listdir_fullpath('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_1985_sent_harm_subs_128')\n",
    "file_names = listdir_fullpath('/explore/nobackup/people/spotter5/cnn_mapping/Russia/l8_sent_collection2_proj_mtbs_unburned_subs_0_128')\n",
    "\n",
    "\n",
    "#shuffle file_names\n",
    "file_names = shuffle(file_names, random_state = 555)\n",
    "\n",
    "\n",
    "print(len(file_names))\n",
    "\n",
    "random.seed(555)\n",
    "# #get train at 80%\n",
    "\n",
    "train_files = random.sample(file_names, k=round(len(file_names) * 0.8))\n",
    "\n",
    "#files at 10%\n",
    "val_files = list(set(file_names) - set(train_files))\n",
    "val_files = random.sample(val_files, k=round(len(file_names) * 0.1))\n",
    "\n",
    "#combine traini and val\n",
    "temp = train_files + val_files\n",
    "#get test files at 10%\n",
    "test_files = list(set(file_names) - set(temp))\n",
    "\n",
    "\n",
    "#convert the lists to pandas dataframes\n",
    "train = pd.DataFrame({'Files': train_files})\n",
    "val = pd.DataFrame({'Files': val_files})\n",
    "test = pd.DataFrame({'Files': test_files})\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/mtbs_training_files.csv')\n",
    "val.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/mtbs_validation_files.csv')\n",
    "test.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/mtbs_testing_files.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf33b61-b3c1-467d-a700-16747eb4787f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faeba86-f2b7-45a0-913b-f6950a9556c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning3]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
