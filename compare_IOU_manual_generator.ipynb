{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2215bc8b-77bf-4352-8bcc-89ca39702e4a",
   "metadata": {},
   "source": [
    "This script will get all the 128x128 numpy files and predict one model using an image generator and one manually. I will also predict manually on the original tif file and compare the three IOU scores. This is to ensure I get the same score for all of them.  If I don't I need to explore why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57965ce-4c1c-4ff4-90d3-d62f4d30bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Setup environment variables\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from MightyMosaic import MightyMosaic\n",
    "import segmentation_models as sm\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "import warnings\n",
    "import glob\n",
    "import tensorflow\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654c627-205e-4b6a-912f-265eaa62ed86",
   "metadata": {},
   "source": [
    "Image generator class and function to predict a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b281a78-a796-49e0-aaac-05da3bdbc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image gen class to be used when predicting\n",
    "min_max_vi = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop = True)\n",
    "min_max_vi = min_max_vi[['6', '7', '8']]\n",
    "\n",
    "class img_gen_vi(tensorflow.keras.utils.Sequence):\n",
    "\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\n",
    "    Inputs are batch size, the image size, the input paths (x) and target paths (y)\n",
    "    \"\"\"\n",
    "\n",
    "    #will need pre defined variables batch_size, img_size, input_img_paths and target_img_paths\n",
    "    def __init__(self, batch_size, img_size, input_img_paths):\n",
    "\t    self.batch_size = batch_size\n",
    "\t    self.img_size = img_size\n",
    "\t    self.input_img_paths = input_img_paths\n",
    "\t    self.target_img_paths = input_img_paths\n",
    "\n",
    "    #number of batches the generator is supposed to produceis the length of the paths divided by the batch siize\n",
    "    def __len__(self):\n",
    "\t    return len(self.input_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_img_paths = self.input_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (x)\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (y)\n",
    "\t\t\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\") #create matrix of zeros which will have the dimension height, wideth, n_bands), 8 is the n_bands\n",
    "        \n",
    "  \n",
    "         #start populating x by enumerating over the input img paths\n",
    "        for j, path in enumerate(batch_img_paths):\n",
    "\n",
    "           #load image\n",
    "            img =  np.round(np.load(path), 3)\n",
    "            \n",
    "            if img.shape[2] == 4:\n",
    "                \n",
    "                img = img[:, :, :-1]\n",
    "\n",
    "            else:\n",
    "                \n",
    "                img = img[:, :, 6:9]\n",
    "\n",
    "            # img = img * 1000\n",
    "            img = img.astype(float)\n",
    "            img = np.round(img, 3)\n",
    "            img[img == 0] = -999\n",
    "\n",
    "            img[np.isnan(img)] = -999\n",
    "\n",
    "\n",
    "            img[img == -999] = np.nan\n",
    "\n",
    "            in_shape = img.shape\n",
    "            \n",
    "            #turn to dataframe to normalize\n",
    "            img = img.reshape(img.shape[0] * img.shape[1], img.shape[2])\n",
    "\t\t\t\n",
    "            img = pd.DataFrame(img)\n",
    "\t\t\t\n",
    "            img.columns = min_max_vi.columns\n",
    "\t\t\t\n",
    "            img = pd.concat([min_max_vi, img]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "            #normalize 0 to 1\n",
    "            img = pd.DataFrame(scaler.fit_transform(img))\n",
    "\t\t\t\n",
    "            img = img.iloc[2:]\n",
    "#\n",
    "#             img = img.values.reshape(in_shape)\n",
    "            img = img.values.reshape(in_shape)\n",
    "\n",
    "#             replace nan with -1\n",
    "            img[np.isnan(img)] = -1\n",
    "\n",
    "#apply standardization\n",
    "# img = normalize(img, axis=(0,1))\n",
    "\n",
    "            img = np.round(img, 3)\n",
    "            #populate x\n",
    "            x[j] = img#[:, :, 4:] index number is not included, \n",
    "\n",
    "\n",
    "        #do tthe same thing for y\n",
    "        y = np.zeros((self.batch_size,) + self.img_size, dtype=\"uint8\")\n",
    "\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "\n",
    "            #load image\n",
    "            img =  np.round(np.load(path), 3)[:, :, -1]\n",
    "\n",
    "            img = img.astype(int)\n",
    "\n",
    "            img[img < 0] = 0\n",
    "            img[img >1] = 0\n",
    "            img[~np.isin(img, [0,1])] = 0\n",
    "\n",
    "            img[np.isnan(img)] = 0\n",
    "            img = img.astype(int)\n",
    "\n",
    "            # img =  tf.keras.utils.to_categorical(img, num_classes = 2)\n",
    "            # y[j] = np.expand_dims(img, 2) \n",
    "            y[j] = img\n",
    "  \n",
    "       \n",
    "    #Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "    # y[j] -= 1\n",
    "\n",
    "        return x, y\n",
    "\n",
    "def predict_model(model, generator, name):\n",
    "    \n",
    "    '''\n",
    "    model: tensorflow model to predict\n",
    "    generator: keras generator with the images to predict on\n",
    "    name: string, model name\\\n",
    "    fid: variable I was looping through\n",
    "    count: count retained earlier\n",
    "    '''\n",
    "    #get the results from the nbac and mtbs model\n",
    "    model_1_res = model.evaluate_generator(generator, 100)\n",
    "    # model_1_res = model.evaluate(models_vi_gen, \n",
    "    #                          steps=20,   # Total number of steps (batches)\n",
    "    #                          workers=4,                  # Number of workers for parallel data loading\n",
    "    #                          use_multiprocessing=True)   # Enable multiprocessing for faster data loading\n",
    "\n",
    "    iou = np.round(model_1_res[-2], 2)\n",
    "    precision = np.round(model_1_res[-5], 2)\n",
    "    recall = np.round(model_1_res[-4], 2)\n",
    "    f1 = np.round(model_1_res[-3], 2)\n",
    "    accuracy = np.round(model_1_res[-1], 2)\n",
    "\n",
    "    #make new dataframe with scores\n",
    "    in_df = pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'IOU': [iou],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F-1': [f1],\n",
    "        'Accuracy': [accuracy]\n",
    "                        }, index=[0])  # Explicitly setting index to [0] for a single row\n",
    "\n",
    "    return in_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed45880-2bb7-46b0-96b5-d88bb525e814",
   "metadata": {},
   "source": [
    "Model to check with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20383cd7-bbc9-4707-8c0e-11231ea7f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_0.tf\", \n",
    "                                     custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                     'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                     'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                     'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b230b72-3294-48fb-8efc-86577630d3a3",
   "metadata": {},
   "source": [
    "Pathways to the original tif and chunked path, uses median_1.tif here. I will run the generator on this one file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a19715-10e1-4af3-aa88-76b720fc98ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "Total execution time: 0.11 minutes\n",
      "            Model   IOU  Precision  Recall   F-1  Accuracy\n",
      "0  Comb_Sliding_1  0.83       0.89    0.92  0.91      0.98\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Input path where the original TIFF files are stored\n",
    "in_path = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_monthly_ndsi_sliding'\n",
    "\n",
    "# Path where the 128x128 chunks are stored (output path from previous script)\n",
    "chunk_path = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_monthly_ndsi_sliding_subs_0_128'\n",
    "\n",
    "#file of interest\n",
    "in_file = 'median_6.tif' #median 1 is bigger\n",
    "\n",
    " # Extract the TIFF ID from file_name, e.g., for 'median_1.tif' the ID is 1\n",
    "tif_id = in_file.split('_')[1].replace('.tif', '')\n",
    "\n",
    "# Loop through the directory of chunks and select the ones associated with the current file_name\n",
    "chunk_files = [f for f in os.listdir(chunk_path) if f.endswith(f'_{tif_id}.npy')]  # Dynamically select files based on file_name\n",
    "\n",
    "#append the full pathway\n",
    "chunk_files = [os.path.join(chunk_path, f) for f in chunk_files]\n",
    "\n",
    "#image size\n",
    "img_size = (128, 128)\n",
    "\n",
    "#batch size\n",
    "batch_size = len(chunk_files)\n",
    "# batch_size = 1\n",
    "\n",
    "#apply the generator\n",
    "models_vi_gen =  img_gen_vi(batch_size, img_size, chunk_files)\n",
    "\n",
    "#predict the model\n",
    "gen_preds = predict_model(model, models_vi_gen, 'Comb_Sliding_1')\n",
    "\n",
    " # End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total time in minutes\n",
    "total_time = (end_time - start_time) / 60\n",
    "print(f\"Total execution time: {total_time:.2f} minutes\")\n",
    "\n",
    "print(gen_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72dca2f-69cd-4a68-a7de-b1f042ddd51c",
   "metadata": {},
   "source": [
    "Return IOU with intersection and union and time to compare to above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8aad73a-f8ee-4e9b-b1a7-c3829ffe5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 0.1408 - unet_output_sup0_activation_loss: 0.0450 - unet_output_sup1_activation_loss: 0.0477 - unet_output_final_activation_loss: 0.0481 - unet_output_sup0_activation_precision: 0.8886 - unet_output_sup0_activation_recall: 0.9644 - unet_output_sup0_activation_f1-score: 0.9249 - unet_output_sup0_activation_iou_score: 0.8604 - unet_output_sup0_activation_accuracy: 0.9833 - unet_output_sup1_activation_precision: 0.8931 - unet_output_sup1_activation_recall: 0.9231 - unet_output_sup1_activation_f1-score: 0.9078 - unet_output_sup1_activation_iou_score: 0.8312 - unet_output_sup1_activation_accuracy: 0.9800 - unet_output_final_activation_precision: 0.8939 - unet_output_final_activation_recall: 0.9235 - unet_output_final_activation_f1-score: 0.9085 - unet_output_final_activation_iou_score: 0.8323 - unet_output_final_activation_accuracy: 0.9801\n",
      "Total execution time: 0.17 minutes\n",
      "            Model  IOU (Model)  IOU (Calculated)  Total Intersection   \n",
      "0  Comb_Sliding_1         0.83          0.862402              136820  \\\n",
      "\n",
      "   Total Union  Precision  Recall   F-1  Accuracy  \n",
      "0       158650       0.89    0.92  0.91      0.98  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def predict_model(model, generator, name):\n",
    "    '''\n",
    "    model: tensorflow model to predict\n",
    "    generator: keras generator with the images to predict on\n",
    "    name: string, model name\n",
    "    '''\n",
    "    # Initialize variables to accumulate intersection and union\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    # Get the results from the model (since generator length is 1)\n",
    "    for i in range(len(generator)):\n",
    "        # Extract the batch of images (x_batch) and ground truth labels (y_true)\n",
    "        x_batch, y_true = generator[i]\n",
    "        \n",
    "        # Iterate through each sample in the batch (81 samples)\n",
    "        for j in range(len(x_batch)):\n",
    "            # Select the j-th image and its corresponding label\n",
    "            x_sample = np.expand_dims(x_batch[j], axis=0)  # Add batch dimension for prediction\n",
    "            y_true_sample = y_true[j]\n",
    "            \n",
    "            # Skip the calculation if y_true_sample is all zeros\n",
    "            if np.all(y_true_sample == 0):\n",
    "                continue\n",
    "            \n",
    "            # Predict on the individual sample\n",
    "            y_pred_sample = model.predict(x_sample, verbose=0)\n",
    "            \n",
    "            # Squeeze the extra dimension in y_pred to match the shape of y_true\n",
    "            y_pred_sample = np.squeeze(y_pred_sample, axis=1)  # Remove the batch dimension\n",
    "            \n",
    "            # Select the first channel from the prediction (assuming binary classification)\n",
    "            y_pred_sample = y_pred_sample[0]  # Taking the first channel out of 3\n",
    "            \n",
    "            # Threshold predictions to binary (0 or 1) if necessary\n",
    "            y_pred_sample = np.where(y_pred_sample > 0.5, 1, 0)\n",
    "\n",
    "            y_pred_sample = y_pred_sample[:, :, 0]\n",
    "            \n",
    "            # Ensure y_pred and y_true have compatible shapes\n",
    "            assert y_pred_sample.shape == y_true_sample.shape, f\"Shape mismatch: y_pred {y_pred_sample.shape} and y_true {y_true_sample.shape}\"\n",
    "            \n",
    "            # Calculate intersection and union for this sample\n",
    "            intersection = np.logical_and(y_pred_sample, y_true_sample).sum()\n",
    "            union = np.logical_or(y_pred_sample, y_true_sample).sum()\n",
    "            \n",
    "            # Accumulate intersection and union\n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "    \n",
    "    # Calculate IOU based on total intersection and total union\n",
    "    iou_calculated = total_intersection / total_union if total_union > 0 else 0\n",
    "    \n",
    "    # Evaluate the model to get metrics including IOU (from model's perspective)\n",
    "    model_1_res = model.evaluate(generator)\n",
    "    \n",
    "    iou_model = np.round(model_1_res[-2], 2)\n",
    "    precision = np.round(model_1_res[-5], 2)\n",
    "    recall = np.round(model_1_res[-4], 2)\n",
    "    f1 = np.round(model_1_res[-3], 2)\n",
    "    accuracy = np.round(model_1_res[-1], 2)\n",
    "    \n",
    "    # Create a new dataframe with scores and the calculated IOU\n",
    "    in_df = pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'IOU (Model)': [iou_model],\n",
    "        'IOU (Calculated)': [iou_calculated],\n",
    "        'Total Intersection': [total_intersection],\n",
    "        'Total Union': [total_union],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F-1': [f1],\n",
    "        'Accuracy': [accuracy]\n",
    "    }, index=[0])  # Explicitly setting index to [0] for a single row\n",
    "    \n",
    "    return in_df\n",
    "\n",
    "\n",
    "# Input path where the original TIFF files are stored\n",
    "in_path = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_monthly_ndsi_sliding'\n",
    "\n",
    "# Path where the 128x128 chunks are stored (output path from previous script)\n",
    "chunk_path = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_monthly_ndsi_sliding_subs_0_128'\n",
    "\n",
    "# File of interest\n",
    "in_file = 'median_6.tif'\n",
    "\n",
    "# Extract the TIFF ID from file_name, e.g., for 'median_1.tif' the ID is 1\n",
    "tif_id = in_file.split('_')[1].replace('.tif', '')\n",
    "\n",
    "# Loop through the directory of chunks and select the ones associated with the current file_name\n",
    "chunk_files = [f for f in os.listdir(chunk_path) if f.endswith(f'_{tif_id}.npy')]  # Dynamically select files based on file_name\n",
    "\n",
    "# Append the full pathway\n",
    "chunk_files = [os.path.join(chunk_path, f) for f in chunk_files]\n",
    "\n",
    "# Image size\n",
    "img_size = (128, 128)\n",
    "\n",
    "# Batch size\n",
    "batch_size = len(chunk_files)\n",
    "\n",
    "# Apply the generator\n",
    "models_vi_gen = img_gen_vi(batch_size, img_size, chunk_files)\n",
    "\n",
    "# Predict the model\n",
    "gen_preds = predict_model(model, models_vi_gen, 'Comb_Sliding_1')\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total time in minutes\n",
    "total_time = (end_time - start_time) / 60\n",
    "print(f\"Total execution time: {total_time:.2f} minutes\")\n",
    "\n",
    "print(gen_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e3f5a3-a597-4700-8c48-bfec76b9b372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624015127639458"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "136820/158650"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25cfcc9-a704-4a79-befc-d31abd09c615",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Now predict on the chunks without the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b004a5-99b1-4e15-8c71-9c5bcde3a30a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Overall IoU for all chunk files: 0.8552701603283642\n"
     ]
    }
   ],
   "source": [
    "# Load min_max dataframe and use columns '6', '7', '8'\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop=True)\n",
    "min_max = min_max[['6', '7', '8']]\n",
    "\n",
    "# Fit the scaler once on the min_max data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(min_max)\n",
    "\n",
    "# Function to normalize the first three bands (6, 7, 8)\n",
    "def norm(img):\n",
    "    img = img[:, :, :3]  # Normalize first three bands\n",
    "    img = img.astype(float)\n",
    "    img = np.round(img, 3)\n",
    "    img[img == 0] = -999\n",
    "    img[np.isnan(img)] = -999\n",
    "    img[img == -999] = np.nan\n",
    "    \n",
    "    in_shape = img.shape\n",
    "    img_flat = img.reshape(-1, img.shape[2])\n",
    "    df_img = pd.DataFrame(img_flat, columns=['6', '7', '8'])\n",
    "    df_img = pd.concat([min_max, df_img]).reset_index(drop=True)\n",
    "    scaled_img = pd.DataFrame(scaler.transform(df_img)).iloc[len(min_max):]\n",
    "    img_scaled = scaled_img.values.reshape(in_shape)\n",
    "    img_scaled[np.isnan(img)] = -1\n",
    "    \n",
    "    return img_scaled\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def calculate_iou(pred, y):\n",
    "    pred_binary = pred > 0.5\n",
    "    y_binary = y > 0.5\n",
    "    intersection = np.logical_and(pred_binary, y_binary).sum()\n",
    "    union = np.logical_or(pred_binary, y_binary).sum()\n",
    "    return intersection, union\n",
    "\n",
    "# Function to process all files in chunk_files without a generator\n",
    "def process_chunks_and_calculate_iou(model, chunk_files):\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for chunk_file in chunk_files:\n",
    "        try:\n",
    "            # Load the chunk (npy file)\n",
    "            img = np.load(chunk_file)\n",
    "            \n",
    "            # Ground truth is the last band\n",
    "            y_true = img[:, :, -1]\n",
    "            y_true = np.round(y_true).astype(int)\n",
    "            y_true[y_true < 0] = 0\n",
    "            y_true[~np.isin(y_true, [0, 1])] = 0\n",
    "            \n",
    "            # Normalize the input data (first three bands)\n",
    "            img_normalized = norm(img)\n",
    "            \n",
    "            # Predict using the model\n",
    "            pred = model.predict(np.expand_dims(img_normalized, axis=0))[0].squeeze()\n",
    "            \n",
    "            # Calculate IoU\n",
    "            intersection, union = calculate_iou(pred, y_true)\n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {chunk_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate the final IoU\n",
    "    overall_iou = total_intersection / total_union if total_union != 0 else 0\n",
    "    return overall_iou\n",
    "\n",
    "# Process all chunks and calculate IoU\n",
    "overall_iou = process_chunks_and_calculate_iou(model, chunk_files)\n",
    "\n",
    "print(f\"Overall IoU for all chunk files: {overall_iou}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d511fff-53c4-4852-a2fe-f93156d2fe29",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Now predict on the original tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f703e24-2933-4a43-9233-c6767ed25fc5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n",
      "IoU for 'median_1.tif': 0.826564719897466\n"
     ]
    }
   ],
   "source": [
    "# Helper function to load and process TIFF files\n",
    "def load_tif(file_path):\n",
    "    img = rioxarray.open_rasterio(file_path).to_numpy()\n",
    "    img = np.moveaxis(img, 0, 2)  # Move bands to last axis\n",
    "    return img\n",
    "\n",
    "# Function to crop two arrays to the smallest common shape\n",
    "def crop_to_smallest(pred, y):\n",
    "    min_height = min(pred.shape[0], y.shape[0])\n",
    "    min_width = min(pred.shape[1], y.shape[1])\n",
    "    return pred[:min_height, :min_width], y[:min_height, :min_width]\n",
    "\n",
    "# Path to the median_1.tif file\n",
    "in_path = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_monthly_ndsi_sliding'\n",
    "tif_file = 'median_1.tif'\n",
    "tif_path = os.path.join(in_path, tif_file)\n",
    "\n",
    "# Load the image from the TIFF file\n",
    "img = load_tif(tif_path)\n",
    "\n",
    "# Extract ground truth (last band)\n",
    "y_true = img[:, :, -1]\n",
    "y_true = np.round(y_true).astype(int)\n",
    "y_true[y_true < 0] = 0\n",
    "y_true[~np.isin(y_true, [0, 1])] = 0\n",
    "\n",
    "# Normalize the input data (first three bands)\n",
    "img_normalized = norm(img)\n",
    "\n",
    "# Predict using the model\n",
    "pred = model.predict(np.expand_dims(img_normalized, axis=0))[0].squeeze()\n",
    "\n",
    "pred, y_true = crop_to_smallest(pred, y_true)\n",
    "\n",
    "# Calculate IoU\n",
    "intersection, union = calculate_iou(pred, y_true)\n",
    "iou = intersection / union if union != 0 else 0\n",
    "\n",
    "print(f\"IoU for 'median_1.tif': {iou}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b44c9-faeb-4404-a34c-7ad8b292390c",
   "metadata": {},
   "source": [
    "Image generator with batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f5997e-070c-4eea-a99e-fc92e09f9016",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Assuming min_max_vi and scaler are already defined as in your original code\n",
    "\n",
    "class img_gen_vi_one(tf.keras.utils.Sequence):\n",
    "\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\n",
    "    Inputs are batch size (now fixed to 1), the image size, the input paths (x), and target paths (y)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size, input_img_paths):\n",
    "        self.batch_size = 1  # Fixed batch size to 1 for individual processing\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = input_img_paths  # Assuming target paths are the same\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_img_paths)  # One batch per image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) corresponding to batch #idx.\"\"\"\n",
    "        \n",
    "        # Get the image path\n",
    "        img_path = self.input_img_paths[idx]\n",
    "        \n",
    "        # Create empty arrays for x (input) and y (ground truth)\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        y = np.zeros((self.batch_size,) + self.img_size, dtype=\"uint8\")\n",
    "        \n",
    "        # Load image\n",
    "        img = np.round(np.load(img_path), 3)\n",
    "        \n",
    "        # Select the appropriate bands for normalization\n",
    "        if img.shape[2] == 4:\n",
    "            img = img[:, :, :-1]  # Drop the last band if it has 4 bands\n",
    "        else:\n",
    "            img = img[:, :, 6:9]  # Select bands 6 to 8 if it has more than 3 bands\n",
    "\n",
    "        # Normalize the image\n",
    "        img = img.astype(float)\n",
    "        img = np.round(img, 3)\n",
    "        img[img == 0] = -999\n",
    "        img[np.isnan(img)] = -999\n",
    "        img[img == -999] = np.nan\n",
    "\n",
    "        in_shape = img.shape\n",
    "        img = img.reshape(img.shape[0] * img.shape[1], img.shape[2])\n",
    "        img = pd.DataFrame(img, columns=min_max_vi.columns)\n",
    "        img = pd.concat([min_max_vi, img]).reset_index(drop=True)\n",
    "        img = pd.DataFrame(scaler.transform(img))\n",
    "        img = img.iloc[len(min_max_vi):]  # Remove the first rows from the min_max scaling\n",
    "        img = img.values.reshape(in_shape)\n",
    "        img[np.isnan(img)] = -1\n",
    "\n",
    "        # Assign the normalized image to the input array\n",
    "        x[0] = img\n",
    "\n",
    "        # Ground truth (y) is the last band\n",
    "        y_img = np.round(np.load(img_path), 3)[:, :, -1]\n",
    "        y_img = y_img.astype(int)\n",
    "        y_img[y_img < 0] = 0\n",
    "        y_img[y_img > 1] = 0\n",
    "        y_img[~np.isin(y_img, [0, 1])] = 0\n",
    "        y_img[np.isnan(y_img)] = 0\n",
    "        y[0] = y_img\n",
    "\n",
    "        return x, y\n",
    "        \n",
    "# Initialize the generator with batch size 1\n",
    "# models_vi_gen = img_gen_vi_one(img_size, chunk_files)\n",
    "\n",
    "# # Predict the model using the generator with batch size 1\n",
    "# gen_preds = predict_model(model, models_vi_gen, 'Comb_Sliding_1')\n",
    "\n",
    "# print(gen_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916351f-0fb6-4893-9bbf-2454e2a37d20",
   "metadata": {},
   "source": [
    "Depending on the results above I can use the image generator or not, I think there was a problem in my spatial evaluations before anyways. I think it was ok actually to use the generator, redo the code to get total predictions from the folds first, then re-do getting spatial on only the test set, and merging those IOU's, there is something wrong there. First do it with one fold, then do it with all to make sure things are staying consistent.  Ideally one script will do it all at the exact same time. Not all folds are done right now for NDSI and NDSI sliding so maybe do those, and match old with the folds that are done.  If something suspicisou re-run the fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbef61d-00c6-4d04-afe9-1d2322b420de",
   "metadata": {},
   "source": [
    "For each of the folds compare the testing set IOU's independently, I will do this for the combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3bd97f9-7756-4579-893c-653c1b3c804f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "\n",
    "# Function to load models for a specific fold\n",
    "def load_models_for_fold(fold):\n",
    "    model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_{fold}_old.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    return model_1, model_2, model_3\n",
    "\n",
    "# Filter function for chunked data\n",
    "def filter_chunked(in_names, chunked, data_type):\n",
    "    \"\"\"\n",
    "    General function to filter chunked data based on in_names and chunked paths.\n",
    "    data_type: 'old', 'ndsi', or 'sliding' to modify paths accordingly.\n",
    "    \"\"\"\n",
    "    filtered_chunked = [name for name in chunked if int(name.split('_')[-1].split('.')[0]) in in_names]\n",
    "    base_path = f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_{data_type}_subs_0_128/\"\n",
    "    return [os.path.join(base_path, i) for i in filtered_chunked]\n",
    "\n",
    "# Main function to process a single fold\n",
    "def process_fold(fold):\n",
    "    # Load models\n",
    "    model_1, model_2, model_3 = load_models_for_fold(fold)\n",
    "\n",
    "    # Load testing data for the fold\n",
    "    testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "\n",
    "    # Load chunked data for old, ndsi, and sliding\n",
    "    chunked_old = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_old_subs_0_128')\n",
    "    chunked_ndsi = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_subs_0_128')\n",
    "    chunked_sliding = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding_subs_0_128')\n",
    "\n",
    "    # Filter chunked data\n",
    "    testing_names_old = filter_chunked(testing_names, chunked_old, 'old')\n",
    "    testing_names_ndsi = filter_chunked(testing_names, chunked_ndsi, 'monthly_ndsi')\n",
    "    testing_names_sliding = filter_chunked(testing_names, chunked_sliding, 'monthly_ndsi_sliding')\n",
    "\n",
    "    # Initialize image generators\n",
    "    img_size = (128, 128)\n",
    "    models_vi_gen_old = img_gen_vi_one(img_size, testing_names_old)\n",
    "    models_vi_gen_ndsi = img_gen_vi_one(img_size, testing_names_ndsi)\n",
    "    models_vi_gen_sliding = img_gen_vi_one(img_size, testing_names_sliding)\n",
    "\n",
    "    # Predict on the models using the generator with batch size 1\n",
    "    gen_preds_old = predict_model(model_1, models_vi_gen_old, f'Comb_Old_{fold}')\n",
    "    gen_preds_ndsi = predict_model(model_2, models_vi_gen_ndsi, f'Comb_NDSI_{fold}')\n",
    "    gen_preds_sliding = predict_model(model_3, models_vi_gen_sliding, f'Comb_Sliding_{fold}')\n",
    "\n",
    "    # Combine results for the current fold\n",
    "    fold_results = pd.concat([gen_preds_old, gen_preds_ndsi, gen_preds_sliding], ignore_index=True)\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "# List of folds to process\n",
    "folds = [0, 2, 4]\n",
    "\n",
    "# Process each fold and combine results\n",
    "all_results = pd.concat([process_fold(fold) for fold in folds], ignore_index=True)\n",
    "\n",
    "# Save final results to CSV\n",
    "# all_results.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/final_iou_results_all_folds.csv', index=False)\n",
    "\n",
    "print(\"Final results saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944780bd-730e-49dc-82cf-800cc03e2916",
   "metadata": {},
   "source": [
    "Get IOU accumulated across all folds, note this isn't really a way we should do this as taking the mean across the 5 after each fold is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795af662-7886-40e2-8eea-fa50c5b591d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 14:02:55.102654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 216\u001b[0m\n\u001b[1;32m    213\u001b[0m folds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]  \u001b[38;5;66;03m# Example folds\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Calculate the IoU across all folds\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m iou_old, iou_ndsi, iou_sliding \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_iou_across_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Print the final IoU values for each model across all folds\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall IoU for old model across all folds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miou_old\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 193\u001b[0m, in \u001b[0;36mcalculate_iou_across_folds\u001b[0;34m(folds)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Process IoU for the current fold\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m fold_iou_old, fold_iou_ndsi, fold_iou_sliding \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Accumulate results\u001b[39;00m\n\u001b[1;32m    196\u001b[0m total_intersection_old \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m fold_iou_old\n",
      "Cell \u001b[0;32mIn[4], line 162\u001b[0m, in \u001b[0;36mprocess_fold\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m    159\u001b[0m testing_names_sliding \u001b[38;5;241m=\u001b[39m filter_chunked(testing_names, chunked_sliding, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly_ndsi_sliding\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Process chunk files for each model and accumulate IoU for old model\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m total_intersection_old, total_union_old \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_chunks_and_calculate_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_names_old\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Process chunk files for NDSI model\u001b[39;00m\n\u001b[1;32m    165\u001b[0m total_intersection_ndsi, total_union_ndsi \u001b[38;5;241m=\u001b[39m process_chunks_and_calculate_iou(model_2, testing_names_ndsi, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndsi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 105\u001b[0m, in \u001b[0;36mprocess_chunks_and_calculate_iou\u001b[0;34m(model, chunk_files, model_type)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_file \u001b[38;5;129;01min\u001b[39;00m chunk_files:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;66;03m# Load the chunk (npy file)\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;66;03m# Ground truth is the last band\u001b[39;00m\n\u001b[1;32m    108\u001b[0m         y_true \u001b[38;5;241m=\u001b[39m img[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/numpy/lib/format.py:801\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    814\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import geopandas as gpd\n",
    "\n",
    "# Function to load models for a specific fold\n",
    "def load_models_for_fold(fold):\n",
    "    model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_{fold}_old.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    return model_1, model_2, model_3\n",
    "\n",
    "# Load min_max dataframe and use columns '6', '7', '8'\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop=True)\n",
    "min_max = min_max[['6', '7', '8']]\n",
    "\n",
    "# Fit the scaler once on the min_max data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(min_max)\n",
    "\n",
    "# Function to normalize the first three bands (6, 7, 8)\n",
    "def norm(img):\n",
    "    img = img[:, :, :3]  # Normalize first three bands\n",
    "    img = img.astype(float)\n",
    "    img = np.round(img, 3)\n",
    "    img[img == 0] = -999\n",
    "    img[np.isnan(img)] = -999\n",
    "    img[img == -999] = np.nan\n",
    "    \n",
    "    in_shape = img.shape\n",
    "    img_flat = img.reshape(-1, img.shape[2])\n",
    "    df_img = pd.DataFrame(img_flat, columns=['6', '7', '8'])\n",
    "    df_img = pd.concat([min_max, df_img]).reset_index(drop=True)\n",
    "    scaled_img = pd.DataFrame(scaler.transform(df_img)).iloc[len(min_max):]\n",
    "    img_scaled = scaled_img.values.reshape(in_shape)\n",
    "    img_scaled[np.isnan(img)] = -1\n",
    "    \n",
    "    return img_scaled\n",
    "\n",
    "# Filter function for chunked data\n",
    "def filter_chunked(in_names, chunked, data_type):\n",
    "    \"\"\"\n",
    "    General function to filter chunked data based on in_names and chunked paths.\n",
    "    data_type: 'old', 'ndsi', or 'sliding' to modify paths accordingly.\n",
    "    \"\"\"\n",
    "    filtered_chunked = [name for name in chunked if int(name.split('_')[-1].split('.')[0]) in in_names]\n",
    "    base_path = f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_{data_type}_subs_0_128/\"\n",
    "    \n",
    "    return [os.path.join(base_path, i) for i in filtered_chunked]\n",
    "\n",
    "\n",
    "# Helper function to load and process TIFF files\n",
    "# def load_tif(file_path, poly_id):\n",
    "#     tif_file = f'median_{poly_id}.tif'\n",
    "#     tif_path = os.path.join(file_path, tif_file)\n",
    "#     img = rioxarray.open_rasterio(tif_path).to_numpy()\n",
    "#     img = np.moveaxis(img, 0, 2)  # Move bands to last axis\n",
    "#     return img\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def calculate_iou(pred, y):\n",
    "    pred_binary = pred > 0.5\n",
    "    y_binary = y > 0.5\n",
    "    intersection = np.logical_and(pred_binary, y_binary).sum()\n",
    "    union = np.logical_or(pred_binary, y_binary).sum()\n",
    "    return intersection, union\n",
    "\n",
    "# Function to crop two arrays to the smallest common shape\n",
    "def crop_to_smallest(pred, y):\n",
    "    min_height = min(pred.shape[0], y.shape[0])\n",
    "    min_width = min(pred.shape[1], y.shape[1])\n",
    "    pred_cropped = pred[:min_height, :min_width]\n",
    "    y_cropped = y[:min_height, :min_width]\n",
    "    return pred_cropped, y_cropped\n",
    "\n",
    "# Function to process all files in chunk_files and calculate IoU\n",
    "def process_chunks_and_calculate_iou(model, chunk_files, model_type):\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for chunk_file in chunk_files:\n",
    "        try:\n",
    "            # Load the chunk (npy file)\n",
    "            img = np.load(chunk_file)\n",
    "            \n",
    "            # Ground truth is the last band\n",
    "            y_true = img[:, :, -1]\n",
    "            y_true = np.round(y_true).astype(int)\n",
    "            y_true[y_true < 0] = 0\n",
    "            y_true[~np.isin(y_true, [0, 1])] = 0\n",
    "            \n",
    "            # Normalize the input data (first three bands)\n",
    "            img_normalized = norm(img)\n",
    "            \n",
    "            # Predict using the model\n",
    "            pred = model.predict(np.expand_dims(img_normalized, axis=0),  verbose=0)[0].squeeze()\n",
    "            \n",
    "            # Crop predictions and ground truth to the smallest common shape\n",
    "            pred, y_true = crop_to_smallest(pred, y_true)\n",
    "            \n",
    "            # Calculate IoU\n",
    "            intersection, union = calculate_iou(pred, y_true)\n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {chunk_file} for {model_type} model: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return total_intersection, total_union\n",
    "\n",
    "# Main function to process a single fold and calculate IoU for old, ndsi, and sliding\n",
    "def process_fold(fold):\n",
    "    # Initialize accumulators for IoU sums\n",
    "    total_intersection_old = 0\n",
    "    total_union_old = 0\n",
    "\n",
    "    total_intersection_ndsi = 0\n",
    "    total_union_ndsi = 0\n",
    "\n",
    "    total_intersection_sliding = 0\n",
    "    total_union_sliding = 0\n",
    "\n",
    "    # Load models\n",
    "    model_1, model_2, model_3 = load_models_for_fold(fold)\n",
    "\n",
    "    # Load testing data for the fold\n",
    "    testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "\n",
    "    # Load chunked data for old, ndsi, and sliding\n",
    "    chunked_old = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_old_subs_0_128')\n",
    "    chunked_ndsi = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_subs_0_128')\n",
    "    chunked_sliding = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding_subs_0_128')\n",
    "\n",
    "    # Filter chunked data based on test names\n",
    "    testing_names_old = filter_chunked(testing_names, chunked_old, 'old')\n",
    "    testing_names_ndsi = filter_chunked(testing_names, chunked_ndsi, 'monthly_ndsi')\n",
    "    testing_names_sliding = filter_chunked(testing_names, chunked_sliding, 'monthly_ndsi_sliding')\n",
    "\n",
    "    # Process chunk files for each model and accumulate IoU for old model\n",
    "    total_intersection_old, total_union_old = process_chunks_and_calculate_iou(model_1, testing_names_old, 'old')\n",
    "    \n",
    "    # Process chunk files for NDSI model\n",
    "    total_intersection_ndsi, total_union_ndsi = process_chunks_and_calculate_iou(model_2, testing_names_ndsi, 'ndsi')\n",
    "\n",
    "    # Process chunk files for sliding NDSI model\n",
    "    total_intersection_sliding, total_union_sliding = process_chunks_and_calculate_iou(model_3, testing_names_sliding, 'sliding')\n",
    "\n",
    "    # Calculate final overall IoUs for each model\n",
    "    overall_iou_old = total_intersection_old / total_union_old if total_union_old != 0 else 0\n",
    "    overall_iou_ndsi = total_intersection_ndsi / total_union_ndsi if total_union_ndsi != 0 else 0\n",
    "    overall_iou_sliding = total_intersection_sliding / total_union_sliding if total_union_sliding != 0 else 0\n",
    "\n",
    "    return overall_iou_old, overall_iou_ndsi, overall_iou_sliding\n",
    "\n",
    "# Main function to calculate IoU across all folds\n",
    "def calculate_iou_across_folds(folds):\n",
    "    # Initialize accumulators for IoU across all folds\n",
    "    total_intersection_old = 0\n",
    "    total_union_old = 0\n",
    "\n",
    "    total_intersection_ndsi = 0\n",
    "    total_union_ndsi = 0\n",
    "\n",
    "    total_intersection_sliding = 0\n",
    "    total_union_sliding = 0\n",
    "\n",
    "    for fold in folds:\n",
    "        print(f\"Processing fold {fold}...\")\n",
    "        \n",
    "        # Process IoU for the current fold\n",
    "        fold_iou_old, fold_iou_ndsi, fold_iou_sliding = process_fold(fold)\n",
    "\n",
    "        # Accumulate results\n",
    "        total_intersection_old += fold_iou_old\n",
    "        total_union_old += fold_iou_old\n",
    "\n",
    "        total_intersection_ndsi += fold_iou_ndsi\n",
    "        total_union_ndsi += fold_iou_ndsi\n",
    "\n",
    "        total_intersection_sliding += fold_iou_sliding\n",
    "        total_union_sliding += fold_iou_sliding\n",
    "\n",
    "    # Calculate overall IoUs for all folds\n",
    "    overall_iou_old = total_intersection_old / total_union_old if total_union_old != 0 else 0\n",
    "    overall_iou_ndsi = total_intersection_ndsi / total_union_ndsi if total_union_ndsi != 0 else 0\n",
    "    overall_iou_sliding = total_intersection_sliding / total_union_sliding if total_union_sliding != 0 else 0\n",
    "\n",
    "    return overall_iou_old, overall_iou_ndsi, overall_iou_sliding\n",
    "\n",
    "# List of folds to process\n",
    "folds = [0, 2, 4]  # Example folds\n",
    "\n",
    "# Calculate the IoU across all folds\n",
    "iou_old, iou_ndsi, iou_sliding = calculate_iou_across_folds(folds)\n",
    "\n",
    "# Print the final IoU values for each model across all folds\n",
    "print(f\"Overall IoU for old model across all folds: {iou_old}\")\n",
    "print(f\"Overall IoU for NDSI model across all folds: {iou_ndsi}\")\n",
    "print(f\"Overall IoU for Sliding NDSI model across all folds: {iou_sliding}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f1a81-f9a3-42e1-9b0c-62d42b61e1f4",
   "metadata": {},
   "source": [
    "Do the above but use image generator and keep track of total intersection and union for all folds in teh respectie models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf5ba0-0468-4832-898e-e0f4db0c1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to load models for a specific fold\n",
    "def load_models_for_fold(fold):\n",
    "    # model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_{fold}_old.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    # model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_{fold}.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    # model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "\n",
    "    model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_{fold}_old.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_sliding_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    return model_1, model_2, model_3\n",
    "\n",
    "# Filter function for chunked data\n",
    "def filter_chunked(in_names, chunked, data_type):\n",
    "    filtered_chunked = [name for name in chunked if int(name.split('_')[-1].split('.')[0]) in in_names]\n",
    "    base_path = f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_{data_type}_subs_0_128/\"\n",
    "    return [os.path.join(base_path, i) for i in filtered_chunked]\n",
    "\n",
    "# Function to predict using model and accumulate IoU across batches\n",
    "def predict_model(model, generator, name):\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for i in range(len(generator)):\n",
    "        x_batch, y_true = generator[i]\n",
    "        for j in range(len(x_batch)):\n",
    "            x_sample = np.expand_dims(x_batch[j], axis=0)\n",
    "            y_true_sample = y_true[j]\n",
    "\n",
    "            if np.all(y_true_sample == 0):\n",
    "                continue\n",
    "            \n",
    "            y_pred_sample = model.predict(x_sample, verbose=0)\n",
    "            y_pred_sample = np.squeeze(y_pred_sample, axis=1)[0]\n",
    "            y_pred_sample = np.where(y_pred_sample > 0.5, 1, 0)\n",
    "            y_pred_sample = y_pred_sample[:, :, 0]\n",
    "            \n",
    "            assert y_pred_sample.shape == y_true_sample.shape, f\"Shape mismatch: y_pred {y_pred_sample.shape} and y_true {y_true_sample.shape}\"\n",
    "            \n",
    "            intersection = np.logical_and(y_pred_sample, y_true_sample).sum()\n",
    "            union = np.logical_or(y_pred_sample, y_true_sample).sum()\n",
    "            \n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "    \n",
    "    iou_calculated = total_intersection / total_union if total_union > 0 else 0\n",
    "    \n",
    "    # Evaluate the model to get metrics including IOU (from model's perspective)\n",
    "    model_1_res = model.evaluate(generator, verbose=0)\n",
    "    \n",
    "    iou_model = np.round(model_1_res[-2], 2)\n",
    "    precision = np.round(model_1_res[-5], 2)\n",
    "    recall = np.round(model_1_res[-4], 2)\n",
    "    f1 = np.round(model_1_res[-3], 2)\n",
    "    accuracy = np.round(model_1_res[-1], 2)\n",
    "    \n",
    "    # Create a dataframe with the results\n",
    "    in_df = pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'IOU (Model)': [iou_model],\n",
    "        'IOU (Calculated)': [iou_calculated],\n",
    "        'Total Intersection': [total_intersection],\n",
    "        'Total Union': [total_union],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F-1': [f1],\n",
    "        'Accuracy': [accuracy]\n",
    "    }, index=[0])\n",
    "    \n",
    "    return in_df\n",
    "\n",
    "# Function to process all folds dynamically for each model\n",
    "def process_all_folds(folds, batch_size, img_size, output_path):\n",
    "    total_intersections = {'old': 0, 'ndsi': 0, 'sliding': 0}\n",
    "    total_unions = {'old': 0, 'ndsi': 0, 'sliding': 0}\n",
    "    results = []\n",
    "\n",
    "    for fold in folds:\n",
    "        # Load models for the current fold\n",
    "        model_1, model_2, model_3 = load_models_for_fold(fold)\n",
    "        \n",
    "        # Load testing data for the fold\n",
    "        testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "\n",
    "        # Load chunked data for old, ndsi, and sliding\n",
    "        chunked_old = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_old_subs_0_128')\n",
    "        chunked_ndsi = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_subs_0_128')\n",
    "        chunked_sliding = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding_subs_0_128')\n",
    "\n",
    "        # Filter chunked data based on test names\n",
    "        testing_names_old = filter_chunked(testing_names, chunked_old, 'old')\n",
    "        testing_names_ndsi = filter_chunked(testing_names, chunked_ndsi, 'monthly_ndsi')\n",
    "        testing_names_sliding = filter_chunked(testing_names, chunked_sliding, 'monthly_ndsi_sliding')\n",
    "\n",
    "        # Generate data for each model\n",
    "        model_vi_gen_old = img_gen_vi(batch_size, img_size, testing_names_old)\n",
    "        model_vi_gen_ndsi = img_gen_vi(batch_size, img_size, testing_names_ndsi)\n",
    "        model_vi_gen_sliding = img_gen_vi(batch_size, img_size, testing_names_sliding)\n",
    "\n",
    "        # Apply the generator and predict for each model\n",
    "        result_old = predict_model(model_1, model_vi_gen_old, f'Comb_Old_{fold}')\n",
    "        result_ndsi = predict_model(model_2, model_vi_gen_ndsi, f'Comb_NDSI_{fold}')\n",
    "        result_sliding = predict_model(model_3, model_vi_gen_sliding, f'Comb_Sliding_{fold}')\n",
    "\n",
    "        results.append(result_old)\n",
    "        results.append(result_ndsi)\n",
    "        results.append(result_sliding)\n",
    "\n",
    "        # Accumulate the intersections and unions\n",
    "        total_intersections['old'] += result_old['Total Intersection'].sum()\n",
    "        total_unions['old'] += result_old['Total Union'].sum()\n",
    "        total_intersections['ndsi'] += result_ndsi['Total Intersection'].sum()\n",
    "        total_unions['ndsi'] += result_ndsi['Total Union'].sum()\n",
    "        total_intersections['sliding'] += result_sliding['Total Intersection'].sum()\n",
    "        total_unions['sliding'] += result_sliding['Total Union'].sum()\n",
    "\n",
    "    # Calculate the final IoU for each model\n",
    "    iou_old_final = total_intersections['old'] / total_unions['old'] if total_unions['old'] != 0 else 0\n",
    "    iou_ndsi_final = total_intersections['ndsi'] / total_unions['ndsi'] if total_unions['ndsi'] != 0 else 0\n",
    "    iou_sliding_final = total_intersections['sliding'] / total_unions['sliding'] if total_unions['sliding'] != 0 else 0\n",
    "\n",
    "    # Create a final results dataframe\n",
    "    final_results = pd.DataFrame({\n",
    "        'Model': ['Overall_Old', 'Overall_NDSI', 'Overall_Sliding'],\n",
    "        'IOU (Calculated)': [iou_old_final, iou_ndsi_final, iou_sliding_final],\n",
    "        'Total Intersection': [total_intersections['old'], total_intersections['ndsi'], total_intersections['sliding']],\n",
    "        'Total Union': [total_unions['old'], total_unions['ndsi'], total_unions['sliding']]\n",
    "    })\n",
    "\n",
    "    # Concatenate fold results with overall results\n",
    "    all_results = pd.concat([pd.concat(results, ignore_index=True), final_results], ignore_index=True)\n",
    "\n",
    "    # Save results to CSV\n",
    "    output_file = os.path.join(output_path, 'russia_all_fold_iou_combined.csv')\n",
    "    all_results.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    # Return the final results\n",
    "    return iou_old_final, iou_ndsi_final, iou_sliding_final\n",
    "\n",
    "# Main entry point\n",
    "# folds = [0, 2, 4]  # List of folds\n",
    "folds = [0, 1, 2]  # List of folds\n",
    "\n",
    "batch_size = 20  # Example batch size\n",
    "img_size = (128, 128)  # Example image size\n",
    "output_path = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp'\n",
    "os.makedirs(output_path, exist_ok = True)\n",
    "\n",
    "# Process all folds and get the final IoU for each model\n",
    "start_time = time.time()\n",
    "iou_old, iou_ndsi, iou_sliding = process_all_folds(folds, batch_size, img_size, output_path)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = (end_time - start_time) / 60\n",
    "print(f\"Total execution time: {total_time:.2f} minutes\")\n",
    "\n",
    "# Print the final IoU for each model across all folds\n",
    "print(f\"Overall IoU for old model across all folds: {iou_old}\")\n",
    "print(f\"Overall IoU for NDSI model across all folds: {iou_ndsi}\")\n",
    "print(f\"Overall IoU for Sliding NDSI model across all folds: {iou_sliding}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99bf3c-457c-40df-b427-4a396d2ce2af",
   "metadata": {},
   "source": [
    "Save results per fold as well as overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f7e35e-c0ec-4a58-b7b7-bec349a971c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/russia_all_fold_iou_combined.csv\n",
      "Total execution time: 416.95 minutes\n",
      "Overall IoU for old model across all folds: 0.8069396442982794\n",
      "Overall IoU for NDSI model across all folds: 0.7328799271405454\n",
      "Overall IoU for Sliding NDSI model across all folds: 0.7347724887126243\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to load models for a specific fold\n",
    "def load_models_for_fold(fold):\n",
    "\n",
    "\n",
    "    # model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_{fold}_old.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    # model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_{fold}.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    # model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_{fold}_old.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_sliding_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    return model_1, model_2, model_3\n",
    "\n",
    "# Filter function for chunked data\n",
    "def filter_chunked(in_names, chunked, data_type):\n",
    "    filtered_chunked = [name for name in chunked if int(name.split('_')[-1].split('.')[0]) in in_names]\n",
    "    base_path = f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_{data_type}_subs_0_128/\"\n",
    "    return [os.path.join(base_path, i) for i in filtered_chunked]\n",
    "\n",
    "# Function to predict using model and accumulate IoU across batches\n",
    "def predict_model(model, generator, name):\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for i in range(len(generator)):\n",
    "        x_batch, y_true = generator[i]\n",
    "        for j in range(len(x_batch)):\n",
    "            x_sample = np.expand_dims(x_batch[j], axis=0)\n",
    "            y_true_sample = y_true[j]\n",
    "\n",
    "            if np.all(y_true_sample == 0):\n",
    "                continue\n",
    "            \n",
    "            y_pred_sample = model.predict(x_sample, verbose=0)\n",
    "            y_pred_sample = np.squeeze(y_pred_sample, axis=1)[0]\n",
    "            y_pred_sample = np.where(y_pred_sample > 0.5, 1, 0)\n",
    "            y_pred_sample = y_pred_sample[:, :, 0]\n",
    "            \n",
    "            assert y_pred_sample.shape == y_true_sample.shape, f\"Shape mismatch: y_pred {y_pred_sample.shape} and y_true {y_true_sample.shape}\"\n",
    "            \n",
    "            intersection = np.logical_and(y_pred_sample, y_true_sample).sum()\n",
    "            union = np.logical_or(y_pred_sample, y_true_sample).sum()\n",
    "            \n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "    \n",
    "    iou_calculated = total_intersection / total_union if total_union > 0 else 0\n",
    "    \n",
    "    # Evaluate the model to get metrics including IOU (from model's perspective)\n",
    "    model_1_res = model.evaluate(generator, verbose=0)\n",
    "    \n",
    "    iou_model = np.round(model_1_res[-2], 2)\n",
    "    precision = np.round(model_1_res[-5], 2)\n",
    "    recall = np.round(model_1_res[-4], 2)\n",
    "    f1 = np.round(model_1_res[-3], 2)\n",
    "    accuracy = np.round(model_1_res[-1], 2)\n",
    "    \n",
    "    # Create a dataframe with the results\n",
    "    in_df = pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'IOU (Model)': [iou_model],\n",
    "        'IOU (Calculated)': [iou_calculated],\n",
    "        'Total Intersection': [total_intersection],\n",
    "        'Total Union': [total_union],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F-1': [f1],\n",
    "        'Accuracy': [accuracy]\n",
    "    }, index=[0])\n",
    "    \n",
    "    return in_df\n",
    "\n",
    "# Function to process all folds dynamically for each model\n",
    "def process_all_folds(folds, batch_size, img_size, output_path):\n",
    "    total_intersections = {'old': 0, 'ndsi': 0, 'sliding': 0}\n",
    "    total_unions = {'old': 0, 'ndsi': 0, 'sliding': 0}\n",
    "    results = []\n",
    "\n",
    "    for fold in folds:\n",
    "        # Load models for the current fold\n",
    "        model_1, model_2, model_3 = load_models_for_fold(fold)\n",
    "        \n",
    "        # Load testing data for the fold\n",
    "        testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "\n",
    "        # Load chunked data for old, ndsi, and sliding\n",
    "        chunked_old = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_old_subs_0_128')\n",
    "        chunked_ndsi = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_subs_0_128')\n",
    "        chunked_sliding = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding_subs_0_128')\n",
    "\n",
    "        # Filter chunked data based on test names\n",
    "        testing_names_old = filter_chunked(testing_names, chunked_old, 'old')\n",
    "        testing_names_ndsi = filter_chunked(testing_names, chunked_ndsi, 'monthly_ndsi')\n",
    "        testing_names_sliding = filter_chunked(testing_names, chunked_sliding, 'monthly_ndsi_sliding')\n",
    "\n",
    "        # Generate data for each model\n",
    "        model_vi_gen_old = img_gen_vi(batch_size, img_size, testing_names_old)\n",
    "        model_vi_gen_ndsi = img_gen_vi(batch_size, img_size, testing_names_ndsi)\n",
    "        model_vi_gen_sliding = img_gen_vi(batch_size, img_size, testing_names_sliding)\n",
    "\n",
    "        # Apply the generator and predict for each model\n",
    "        result_old = predict_model(model_1, model_vi_gen_old, f'Comb_Old_{fold}')\n",
    "        result_ndsi = predict_model(model_2, model_vi_gen_ndsi, f'Comb_NDSI_{fold}')\n",
    "        result_sliding = predict_model(model_3, model_vi_gen_sliding, f'Comb_Sliding_{fold}')\n",
    "\n",
    "        results.append(result_old)\n",
    "        results.append(result_ndsi)\n",
    "        results.append(result_sliding)\n",
    "\n",
    "        # Accumulate the intersections and unions\n",
    "        total_intersections['old'] += result_old['Total Intersection'].sum()\n",
    "        total_unions['old'] += result_old['Total Union'].sum()\n",
    "        total_intersections['ndsi'] += result_ndsi['Total Intersection'].sum()\n",
    "        total_unions['ndsi'] += result_ndsi['Total Union'].sum()\n",
    "        total_intersections['sliding'] += result_sliding['Total Intersection'].sum()\n",
    "        total_unions['sliding'] += result_sliding['Total Union'].sum()\n",
    "\n",
    "        # Save IOU for each fold\n",
    "        fold_iou = pd.concat([result_old, result_ndsi, result_sliding])\n",
    "        fold_output_file = os.path.join(output_path, f'russia_{fold}_iou.csv')\n",
    "        fold_iou.to_csv(fold_output_file, index=False)\n",
    "\n",
    "    # Calculate the final IoU for each model\n",
    "    iou_old_final = total_intersections['old'] / total_unions['old'] if total_unions['old'] != 0 else 0\n",
    "    iou_ndsi_final = total_intersections['ndsi'] / total_unions['ndsi'] if total_unions['ndsi'] != 0 else 0\n",
    "    iou_sliding_final = total_intersections['sliding'] / total_unions['sliding'] if total_unions['sliding'] != 0 else 0\n",
    "\n",
    "    # Create a final results dataframe\n",
    "    final_results = pd.DataFrame({\n",
    "        'Model': ['Overall_Old', 'Overall_NDSI', 'Overall_Sliding'],\n",
    "        'IOU (Calculated)': [iou_old_final, iou_ndsi_final, iou_sliding_final],\n",
    "        'Total Intersection': [total_intersections['old'], total_intersections['ndsi'], total_intersections['sliding']],\n",
    "        'Total Union': [total_unions['old'], total_unions['ndsi'], total_unions['sliding']]\n",
    "    })\n",
    "\n",
    "    # Concatenate fold results with overall results\n",
    "    all_results = pd.concat([pd.concat(results, ignore_index=True), final_results], ignore_index=True)\n",
    "\n",
    "    # Save results to CSV\n",
    "    output_file = os.path.join(output_path, 'russia_all_fold_iou_combined.csv')\n",
    "    all_results.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    # Return the final results\n",
    "    return iou_old_final, iou_ndsi_final, iou_sliding_final\n",
    "\n",
    "# Main entry point\n",
    "# folds = [0, 2, 4]  # List of folds\n",
    "folds = [0, 1, 2]  # List of folds\n",
    "\n",
    "batch_size = 20  # Example batch size\n",
    "img_size = (128, 128)  # Example image size\n",
    "output_path = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Process all folds and get the final IoU for each model\n",
    "start_time = time.time()\n",
    "iou_old, iou_ndsi, iou_sliding = process_all_folds(folds, batch_size, img_size, output_path)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = (end_time - start_time) / 60\n",
    "print(f\"Total execution time: {total_time:.2f} minutes\")\n",
    "\n",
    "# Print the final IoU for each model across all folds\n",
    "print(f\"Overall IoU for old model across all folds: {iou_old}\")\n",
    "print(f\"Overall IoU for NDSI model across all folds: {iou_ndsi}\")\n",
    "print(f\"Overall IoU for Sliding NDSI model across all folds: {iou_sliding}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad80b15f-ba6f-4bdb-b336-261b94942d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f31e94-f06d-4c71-a581-e845f88d6830",
   "metadata": {},
   "source": [
    "Now get the IOU saved per ecoregion, we can't use a generator for this I don't think"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a9d91-fcfc-4682-be21-86242ec921dc",
   "metadata": {},
   "source": [
    "Better way with all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4063d65-f33c-4fce-9f23-c104f05ffbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "Processing ecoregion Montane Sub-Arctic...\n",
      "Processing fold 0 for ecoregion Montane Sub-Arctic...\n",
      "Processing fold 2 for ecoregion Montane Sub-Arctic...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 187\u001b[0m\n\u001b[1;32m    184\u001b[0m all_ecoregions \u001b[38;5;241m=\u001b[39m eco[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecoregion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Calculate the IoU across all ecoregions and folds\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m iou_df \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_iou_across_folds_ecoregion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_ecoregions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Save the results to CSV\u001b[39;00m\n\u001b[1;32m    190\u001b[0m iou_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/explore/nobackup/people/spotter5/cnn_mapping/Russia/iou_ecoregion_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 154\u001b[0m, in \u001b[0;36mcalculate_iou_across_folds_ecoregion\u001b[0;34m(ecoregions, eco_df, folds)\u001b[0m\n\u001b[1;32m    152\u001b[0m intersection_old, union_old \u001b[38;5;241m=\u001b[39m process_chunks_and_calculate_iou(model_1, chunked_old_files)\n\u001b[1;32m    153\u001b[0m intersection_ndsi, union_ndsi \u001b[38;5;241m=\u001b[39m process_chunks_and_calculate_iou(model_2, chunked_ndsi_files)\n\u001b[0;32m--> 154\u001b[0m intersection_sliding, union_sliding \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_chunks_and_calculate_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked_sliding_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Accumulate results for this fold\u001b[39;00m\n\u001b[1;32m    157\u001b[0m total_intersection_old \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m intersection_old\n",
      "Cell \u001b[0;32mIn[1], line 89\u001b[0m, in \u001b[0;36mprocess_chunks_and_calculate_iou\u001b[0;34m(model, chunk_files)\u001b[0m\n\u001b[1;32m     86\u001b[0m img_normalized \u001b[38;5;241m=\u001b[39m norm(img)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Calculate IoU\u001b[39;00m\n\u001b[1;32m     92\u001b[0m intersection, union \u001b[38;5;241m=\u001b[39m calculate_iou(pred, y_true)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py:2317\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2309\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2310\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2311\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2314\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2315\u001b[0m         )\n\u001b[0;32m-> 2317\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/data_adapter.py:1579\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/data_adapter.py:1259\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1258\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1274\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/data_adapter.py:306\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# performance.\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    309\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2294\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2292\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2293\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2294\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2296\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2297\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2298\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2301\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2302\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5499\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5499\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5501\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5503\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5504\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m   5505\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m   5506\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   5507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5510\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m   5511\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m def_function\u001b[38;5;241m.\u001b[39mfunctions_run_eagerly():\n\u001b[1;32m    256\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    257\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_tf_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefun_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m fn_factory()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:239\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function\u001b[0;34m(defun_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrace_tf_function\u001b[39m(defun_kwargs):\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;66;03m# Note: wrapper_helper will apply autograph based on context.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;129;43m@eager_function\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefun_with_attributes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_specs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m      \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefun_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 239\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mwrapped_fn\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=missing-docstring\u001b[39;49;00m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mret\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mret\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/quarantine.py:410\u001b[0m, in \u001b[0;36mdefun_with_attributes.<locals>.decorated\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m   name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf_decorator\u001b[38;5;241m.\u001b[39mmake_decorator(\n\u001b[1;32m    409\u001b[0m     function,\n\u001b[0;32m--> 410\u001b[0m     \u001b[43mtracing_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracingCompiler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce_retracing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_retracing\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:107\u001b[0m, in \u001b[0;36mTracingCompiler.__init__\u001b[0;34m(self, python_function, name, input_signature, attributes, autograph, autograph_options, reduce_retracing, capture_by_value, jit_compile)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_function \u001b[38;5;241m=\u001b[39m python_function\n\u001b[1;32m    106\u001b[0m pure_function \u001b[38;5;241m=\u001b[39m attributes \u001b[38;5;129;01mand\u001b[39;00m monomorphic_function\u001b[38;5;241m.\u001b[39mIMPLEMENTS_ATTRIBUTE_NAME \u001b[38;5;129;01min\u001b[39;00m attributes\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctionSpec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_function_and_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpure_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autograph \u001b[38;5;241m=\u001b[39m autograph\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:66\u001b[0m, in \u001b[0;36mFunctionSpec.from_function_and_signature\u001b[0;34m(cls, python_function, input_signature, is_pure, jit_compile)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a FunctionSpec instance given a python function and signature.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m  instance of FunctionSpec\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m _validate_signature(input_signature)\n\u001b[0;32m---> 66\u001b[0m \u001b[43m_validate_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m fullargspec \u001b[38;5;241m=\u001b[39m tf_inspect\u001b[38;5;241m.\u001b[39mgetfullargspec(python_function)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Checks if the `fullargspec` contains self or cls as its first argument.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:579\u001b[0m, in \u001b[0;36m_validate_python_function\u001b[0;34m(python_function, input_signature)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpython_function\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a callable object.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m   fullargspec \u001b[38;5;241m=\u001b[39m \u001b[43mtf_inspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfullargspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(fullargspec\u001b[38;5;241m.\u001b[39mkwonlyargs) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(fullargspec\u001b[38;5;241m.\u001b[39mkwonlydefaults \u001b[38;5;129;01mor\u001b[39;00m ()):\n\u001b[1;32m    581\u001b[0m     nodefault_kwonlyargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(fullargspec\u001b[38;5;241m.\u001b[39mkwonlyargs)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning3/lib/python3.10/site-packages/tensorflow/python/util/tf_inspect.py:247\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has some keyword-only arguments, which are not\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    242\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m supported: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_default_values\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    244\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ArgSpec(args, varargs, keywords, \u001b[38;5;28mtuple\u001b[39m(all_defaults[first_default:]))\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetfullargspec\u001b[39m(obj):\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"TFDecorator-aware replacement for `inspect.getfullargspec`.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m  This wrapper emulates `inspect.getfullargspec` in[^)]* Python2.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    directly on the callable.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m   decorators, target \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(obj)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import geopandas as gpd\n",
    "\n",
    "# Function to load models for a specific fold\n",
    "def load_models_for_fold(fold):\n",
    "    model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_{fold}_old.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    return model_1, model_2, model_3\n",
    "\n",
    "# Load min_max dataframe and use columns '6', '7', '8'\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop=True)\n",
    "min_max = min_max[['6', '7', '8']]\n",
    "\n",
    "# Fit the scaler once on the min_max data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(min_max)\n",
    "\n",
    "# Function to normalize the first three bands (6, 7, 8)\n",
    "def norm(img):\n",
    "    img = img[:, :, :3]  # Normalize first three bands\n",
    "    img = img.astype(float)\n",
    "    img = np.round(img, 3)\n",
    "    img[img == 0] = -999\n",
    "    img[np.isnan(img)] = -999\n",
    "    img[img == -999] = np.nan\n",
    "    \n",
    "    in_shape = img.shape\n",
    "    img_flat = img.reshape(-1, img.shape[2])\n",
    "    df_img = pd.DataFrame(img_flat, columns=['6', '7', '8'])\n",
    "    df_img = pd.concat([min_max, df_img]).reset_index(drop=True)\n",
    "    scaled_img = pd.DataFrame(scaler.transform(df_img)).iloc[len(min_max):]\n",
    "    img_scaled = scaled_img.values.reshape(in_shape)\n",
    "    img_scaled[np.isnan(img)] = -1\n",
    "    \n",
    "    return img_scaled\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def calculate_iou(pred, y):\n",
    "    pred_binary = pred > 0.5\n",
    "    y_binary = y > 0.5\n",
    "    intersection = np.logical_and(pred_binary, y_binary).sum()\n",
    "    union = np.logical_or(pred_binary, y_binary).sum()\n",
    "    return intersection, union\n",
    "\n",
    "# Function to process all files in chunk_files and calculate IoU\n",
    "def process_chunks_and_calculate_iou(model, chunk_files):\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for chunk_file in chunk_files:\n",
    "        try:\n",
    "            # Load the chunk (npy file)\n",
    "            img = np.load(chunk_file)\n",
    "            \n",
    "            # Ground truth is the last band\n",
    "            y_true = img[:, :, -1]\n",
    "            y_true = np.round(y_true).astype(int)\n",
    "            y_true[y_true < 0] = 0\n",
    "            y_true[~np.isin(y_true, [0, 1])] = 0\n",
    "            \n",
    "            # Normalize the input data (first three bands)\n",
    "            img_normalized = norm(img)\n",
    "            \n",
    "            # Predict using the model\n",
    "            pred = model.predict(np.expand_dims(img_normalized, axis=0), verbose=0)[0].squeeze()\n",
    "            \n",
    "            # Calculate IoU\n",
    "            intersection, union = calculate_iou(pred, y_true)\n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {chunk_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return total_intersection, total_union\n",
    "\n",
    "# Main function to calculate IoU for all ecoregions and folds\n",
    "def calculate_iou_across_folds_ecoregion(ecoregions, eco_df, folds):\n",
    "    iou_results = []\n",
    "    \n",
    "    # Loop through each ecoregion\n",
    "    for ecoregion in ecoregions:\n",
    "        print(f\"Processing ecoregion {ecoregion}...\")\n",
    "\n",
    "        total_intersection_old = 0\n",
    "        total_union_old = 0\n",
    "        total_intersection_ndsi = 0\n",
    "        total_union_ndsi = 0\n",
    "        total_intersection_sliding = 0\n",
    "        total_union_sliding = 0\n",
    "        \n",
    "        # Get IDs in this ecoregion\n",
    "        sub_eco = eco_df[eco_df['ecoregion'] == ecoregion]\n",
    "        \n",
    "        for fold in folds:\n",
    "            print(f\"Processing fold {fold} for ecoregion {ecoregion}...\")\n",
    "            \n",
    "            # Load models for the fold\n",
    "            model_1, model_2, model_3 = load_models_for_fold(fold)\n",
    "            \n",
    "            # Load testing data for the fold\n",
    "            testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "            \n",
    "            # Filter ecoregion and testing names\n",
    "            sub_fold = sub_eco[sub_eco['ID'].isin(testing_names)]\n",
    "            fold_ids = sub_fold['ID'].unique().tolist()\n",
    "            \n",
    "            if len(fold_ids) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Load chunked data\n",
    "            old_base_path = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_old_subs_0_128'\n",
    "            ndsi_base_path = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_subs_0_128'\n",
    "            sliding_base_path = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding_subs_0_128'\n",
    "            \n",
    "            # List all files in the directories\n",
    "            chunked_old = os.listdir(old_base_path)\n",
    "            chunked_ndsi = os.listdir(ndsi_base_path)\n",
    "            chunked_sliding = os.listdir(sliding_base_path)\n",
    "            \n",
    "            # Filter chunked data by fold IDs and include full paths\n",
    "            chunked_old_files = [os.path.join(old_base_path, f) for f in chunked_old if int(f.split('_')[-1].split('.')[0]) in fold_ids]\n",
    "            chunked_ndsi_files = [os.path.join(ndsi_base_path, f) for f in chunked_ndsi if int(f.split('_')[-1].split('.')[0]) in fold_ids]\n",
    "            chunked_sliding_files = [os.path.join(sliding_base_path, f) for f in chunked_sliding if int(f.split('_')[-1].split('.')[0]) in fold_ids]\n",
    "\n",
    "            # Process and calculate IoU for each model\n",
    "            intersection_old, union_old = process_chunks_and_calculate_iou(model_1, chunked_old_files)\n",
    "            intersection_ndsi, union_ndsi = process_chunks_and_calculate_iou(model_2, chunked_ndsi_files)\n",
    "            intersection_sliding, union_sliding = process_chunks_and_calculate_iou(model_3, chunked_sliding_files)\n",
    "            \n",
    "            # Accumulate results for this fold\n",
    "            total_intersection_old += intersection_old\n",
    "            total_union_old += union_old\n",
    "            total_intersection_ndsi += intersection_ndsi\n",
    "            total_union_ndsi += union_ndsi\n",
    "            total_intersection_sliding += intersection_sliding\n",
    "            total_union_sliding += union_sliding\n",
    "        \n",
    "        # Calculate final IoU for this ecoregion across all folds\n",
    "        iou_old = total_intersection_old / total_union_old if total_union_old != 0 else 0\n",
    "        iou_ndsi = total_intersection_ndsi / total_union_ndsi if total_union_ndsi != 0 else 0\n",
    "        iou_sliding = total_intersection_sliding / total_union_sliding if total_union_sliding != 0 else 0\n",
    "        \n",
    "        # Store the results\n",
    "        iou_results.append({\n",
    "            'ecoregion': ecoregion,\n",
    "            'iou_old': iou_old,\n",
    "            'iou_ndsi': iou_ndsi,\n",
    "            'iou_sliding': iou_sliding\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(iou_results)\n",
    "\n",
    "# List of folds to process\n",
    "folds = [0, 2, 4]  # Adjust the number of folds if necessary\n",
    "\n",
    "# Load ecoregion shapefile\n",
    "eco = gpd.read_file('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_good_eco_clip.shp')\n",
    "all_ecoregions = eco['ecoregion'].unique().tolist()\n",
    "\n",
    "# Calculate the IoU across all ecoregions and folds\n",
    "iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds)\n",
    "\n",
    "# Save the results to CSV\n",
    "iou_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/iou_ecoregion_results.csv', index=False)\n",
    "\n",
    "# Print the final IoU values for each ecoregion\n",
    "print(iou_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92552b30-cdbd-4edb-8700-53104883aacc",
   "metadata": {},
   "source": [
    "Do the ecoregion level calculations using the generator, but which will calculate the IoU by summing the intersection and union manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10635b0-8aed-4aef-8b73-541980e9512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ecoregion Montane Sub-Arctic...\n",
      "Processing fold 0 for ecoregion Montane Sub-Arctic...\n",
      "Processing fold 2 for ecoregion Montane Sub-Arctic...\n",
      "Processing fold 4 for ecoregion Montane Sub-Arctic...\n",
      "Processing ecoregion Arctic Deserts and Tundra...\n",
      "Processing fold 0 for ecoregion Arctic Deserts and Tundra...\n",
      "Processing fold 2 for ecoregion Arctic Deserts and Tundra...\n",
      "Processing fold 4 for ecoregion Arctic Deserts and Tundra...\n",
      "Processing ecoregion Wetlands...\n",
      "Processing fold 0 for ecoregion Wetlands...\n",
      "Processing fold 2 for ecoregion Wetlands...\n",
      "Processing fold 4 for ecoregion Wetlands...\n",
      "Processing ecoregion Montane Boreal...\n",
      "Processing fold 0 for ecoregion Montane Boreal...\n",
      "Processing fold 2 for ecoregion Montane Boreal...\n",
      "Processing fold 4 for ecoregion Montane Boreal...\n",
      "Processing ecoregion Central Taiga...\n",
      "Processing fold 0 for ecoregion Central Taiga...\n",
      "Processing fold 2 for ecoregion Central Taiga...\n",
      "Processing fold 4 for ecoregion Central Taiga...\n",
      "Processing ecoregion Northern Taiga...\n",
      "Processing fold 0 for ecoregion Northern Taiga...\n",
      "Processing fold 2 for ecoregion Northern Taiga...\n",
      "Processing fold 4 for ecoregion Northern Taiga...\n",
      "Processing ecoregion Montane Sub-Boreal...\n",
      "Processing fold 0 for ecoregion Montane Sub-Boreal...\n",
      "Processing fold 2 for ecoregion Montane Sub-Boreal...\n",
      "Processing fold 4 for ecoregion Montane Sub-Boreal...\n",
      "Processing ecoregion Forest Tundra...\n",
      "Processing fold 0 for ecoregion Forest Tundra...\n",
      "Processing fold 2 for ecoregion Forest Tundra...\n",
      "Processing fold 4 for ecoregion Forest Tundra...\n",
      "Processing ecoregion Southern Taiga...\n",
      "Processing fold 0 for ecoregion Southern Taiga...\n",
      "Processing fold 2 for ecoregion Southern Taiga...\n",
      "Processing fold 4 for ecoregion Southern Taiga...\n",
      "Processing ecoregion Forest Steppe...\n",
      "Processing fold 0 for ecoregion Forest Steppe...\n",
      "Processing fold 2 for ecoregion Forest Steppe...\n",
      "WARNING:tensorflow:5 out of the last 1859 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14c896263be0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 323 calls to <function Model.make_test_function.<locals>.test_function at 0x14c95df98310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x14c8e220a200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Processing fold 4 for ecoregion Forest Steppe...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fold_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 209\u001b[0m\n\u001b[1;32m    203\u001b[0m iou_per_fold_df, final_iou_df \u001b[38;5;241m=\u001b[39m calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, batch_size, img_size)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Save the results to CSV\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# iou_per_fold_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/combined_iou_ecoregion_folds.csv', index=False)\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# final_iou_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/combined_iou_ecoregion_final.csv', index=False)\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m \u001b[43mfold_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/russia_iou_ecoregion_folds.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    210\u001b[0m final_iou_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/russia_iou_ecoregion_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Print the final IoU values for each ecoregion\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fold_df' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "\n",
    "# Function to load models for a specific fold\n",
    "def load_models_for_fold(fold):\n",
    "    # model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_{fold}_old.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    # model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_{fold}.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    # model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\", \n",
    "    #                                      custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "    #                                                      'recall': sm.metrics.Recall(threshold=0.5),\n",
    "    #                                                      'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "    #                                                      'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_{fold}_old.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/russia_good_no_regularize_ndsi_sliding_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "    return model_1, model_2, model_3\n",
    "\n",
    "# Function to filter chunked data for specific ecoregions\n",
    "def filter_chunked(in_names, chunked, data_type):\n",
    "    filtered_chunked = [name for name in chunked if int(name.split('_')[-1].split('.')[0]) in in_names]\n",
    "    base_path = f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_{data_type}_subs_0_128/\"\n",
    "    return [os.path.join(base_path, i) for i in filtered_chunked]\n",
    "\n",
    "# Function to predict using model and accumulate IoU using generator\n",
    "def predict_model_with_generator(model, generator, name):\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for i in range(len(generator)):\n",
    "        x_batch, y_true = generator[i]\n",
    "        for j in range(len(x_batch)):\n",
    "            x_sample = np.expand_dims(x_batch[j], axis=0)\n",
    "            y_true_sample = y_true[j]\n",
    "\n",
    "            if np.all(y_true_sample == 0):\n",
    "                continue\n",
    "            \n",
    "            y_pred_sample = model.predict(x_sample, verbose=0)\n",
    "            y_pred_sample = np.squeeze(y_pred_sample, axis=1)[0]\n",
    "            y_pred_sample = np.where(y_pred_sample > 0.5, 1, 0)\n",
    "            y_pred_sample = y_pred_sample[:, :, 0]\n",
    "            \n",
    "            intersection = np.logical_and(y_pred_sample, y_true_sample).sum()\n",
    "            union = np.logical_or(y_pred_sample, y_true_sample).sum()\n",
    "            \n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "\n",
    "    iou_calculated = total_intersection / total_union if total_union > 0 else 0\n",
    "    \n",
    "    # Evaluate the model to get metrics including IOU (from model's perspective)\n",
    "    model_1_res = model.evaluate(generator, verbose=0)\n",
    "    \n",
    "    iou_model = np.round(model_1_res[-2], 2)\n",
    "    precision = np.round(model_1_res[-5], 2)\n",
    "    recall = np.round(model_1_res[-4], 2)\n",
    "    f1 = np.round(model_1_res[-3], 2)\n",
    "    accuracy = np.round(model_1_res[-1], 2)\n",
    "    \n",
    "    # Create a dataframe with the results\n",
    "    in_df = pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'IOU (Model)': [iou_model],\n",
    "        'IOU (Calculated)': [iou_calculated],\n",
    "        'Total Intersection': [total_intersection],\n",
    "        'Total Union': [total_union],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F-1': [f1],\n",
    "        'Accuracy': [accuracy]\n",
    "    }, index=[0])\n",
    "    \n",
    "    return in_df, iou_calculated\n",
    "\n",
    "# Main function to calculate IoU for all ecoregions and folds\n",
    "def calculate_iou_across_folds_ecoregion(ecoregions, eco_df, folds, batch_size, img_size):\n",
    "    iou_results = []\n",
    "    \n",
    "    for ecoregion in ecoregions:\n",
    "        print(f\"Processing ecoregion {ecoregion}...\")\n",
    "\n",
    "        total_intersections = {'old': 0, 'ndsi': 0, 'sliding': 0}\n",
    "        total_unions = {'old': 0, 'ndsi': 0, 'sliding': 0}\n",
    "        iou_per_fold = []\n",
    "\n",
    "        sub_eco = eco_df[eco_df['ecoregion'] == ecoregion]\n",
    "        \n",
    "        for fold in folds:\n",
    "            print(f\"Processing fold {fold} for ecoregion {ecoregion}...\")\n",
    "            \n",
    "            # Load models for the fold\n",
    "            model_1, model_2, model_3 = load_models_for_fold(fold)\n",
    "            \n",
    "            # Load testing data for the fold\n",
    "            testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "            \n",
    "            # Filter ecoregion and testing names\n",
    "            sub_fold = sub_eco[sub_eco['ID'].isin(testing_names)]\n",
    "            fold_ids = sub_fold['ID'].unique().tolist()\n",
    "            \n",
    "            if len(fold_ids) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Load chunked data\n",
    "            chunked_old = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_old_subs_0_128')\n",
    "            chunked_ndsi = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_subs_0_128')\n",
    "            chunked_sliding = os.listdir('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding_subs_0_128')\n",
    "            \n",
    "            # Filter chunked data by fold IDs and include full paths\n",
    "            testing_names_old = filter_chunked(fold_ids, chunked_old, 'old')\n",
    "            testing_names_ndsi = filter_chunked(fold_ids, chunked_ndsi, 'monthly_ndsi')\n",
    "            testing_names_sliding = filter_chunked(fold_ids, chunked_sliding, 'monthly_ndsi_sliding')\n",
    "\n",
    "            # Generate data for each model\n",
    "            model_vi_gen_old = img_gen_vi(batch_size, img_size, testing_names_old)\n",
    "            model_vi_gen_ndsi = img_gen_vi(batch_size, img_size, testing_names_ndsi)\n",
    "            model_vi_gen_sliding = img_gen_vi(batch_size, img_size, testing_names_sliding)\n",
    "\n",
    "            # Apply the generator and predict for each model\n",
    "            result_old, iou_old = predict_model_with_generator(model_1, model_vi_gen_old, f'Comb_Old_{fold}')\n",
    "            result_ndsi, iou_ndsi = predict_model_with_generator(model_2, model_vi_gen_ndsi, f'Comb_NDSI_{fold}')\n",
    "            result_sliding, iou_sliding = predict_model_with_generator(model_3, model_vi_gen_sliding, f'Comb_Sliding_{fold}')\n",
    "            \n",
    "            # Record IoU for this fold\n",
    "            iou_per_fold.append({\n",
    "                'ecoregion': ecoregion,\n",
    "                'fold': fold,\n",
    "                'iou_old': iou_old,\n",
    "                'iou_ndsi': iou_ndsi,\n",
    "                'iou_sliding': iou_sliding\n",
    "            })\n",
    "\n",
    "            # Accumulate the intersections and unions\n",
    "            total_intersections['old'] += result_old['Total Intersection'].sum()\n",
    "            total_unions['old'] += result_old['Total Union'].sum()\n",
    "            total_intersections['ndsi'] += result_ndsi['Total Intersection'].sum()\n",
    "            total_unions['ndsi'] += result_ndsi['Total Union'].sum()\n",
    "            total_intersections['sliding'] += result_sliding['Total Intersection'].sum()\n",
    "            total_unions['sliding'] += result_sliding['Total Union'].sum()\n",
    "\n",
    "        # Calculate final IoU for this ecoregion across all folds using the sum of intersections and unions\n",
    "        iou_old_final = total_intersections['old'] / total_unions['old'] if total_unions['old'] != 0 else 0\n",
    "        iou_ndsi_final = total_intersections['ndsi'] / total_unions['ndsi'] if total_unions['ndsi'] != 0 else 0\n",
    "        iou_sliding_final = total_intersections['sliding'] / total_unions['sliding'] if total_unions['sliding'] != 0 else 0\n",
    "        \n",
    "        # Store final results\n",
    "        iou_results.append({\n",
    "            'ecoregion': ecoregion,\n",
    "            'final_iou_old': iou_old_final,\n",
    "            'final_iou_ndsi': iou_ndsi_final,\n",
    "            'final_iou_sliding': iou_sliding_final\n",
    "        })\n",
    "\n",
    "    # Return fold-specific and final IoU results\n",
    "    return pd.DataFrame(iou_per_fold), pd.DataFrame(iou_results)\n",
    "\n",
    "# List of folds to process\n",
    "folds = [0, 2, 4]\n",
    "\n",
    "# Load ecoregion shapefile\n",
    "eco = gpd.read_file('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_good_eco_clip.shp')\n",
    "all_ecoregions = eco['ecoregion'].unique().tolist()\n",
    "\n",
    "# Parameters for image generator\n",
    "batch_size = 20\n",
    "img_size = (128, 128)\n",
    "\n",
    "start_time = time.time()\n",
    "# Calculate IoU across all ecoregions and folds\n",
    "iou_per_fold_df, final_iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, batch_size, img_size)\n",
    "\n",
    "# Save the results to CSV\n",
    "# iou_per_fold_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/combined_iou_ecoregion_folds.csv', index=False)\n",
    "# final_iou_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/combined_iou_ecoregion_final.csv', index=False)\n",
    "\n",
    "iou_per_fold_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/russia_iou_ecoregion_folds.csv', index=False)\n",
    "final_iou_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/spatial_compare_temp/russia_iou_ecoregion_final.csv', index=False)\n",
    "\n",
    "# Print the final IoU values for each ecoregion\n",
    "print(final_iou_df)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = (end_time - start_time) / 60\n",
    "print(f\"Total execution time: {total_time:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b693ae-ec97-486f-b2f1-9acf06cd28b7",
   "metadata": {},
   "source": [
    "Maybe it is faster to predict just on the actual tif files not the chunks, lets make a script to do that, note this actually results in tensorflow issues as it prefers same sized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55f77fa-8ba7-4177-987d-86078f0e876d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "Processing ecoregion Montane Sub-Arctic...\n",
      "Processing fold 0 for ecoregion Montane Sub-Arctic...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1458d02dfa30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x144f74a36320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Processing fold 2 for ecoregion Montane Sub-Arctic...\n",
      "Processing fold 4 for ecoregion Montane Sub-Arctic...\n",
      "Processing ecoregion Arctic Deserts and Tundra...\n",
      "Processing fold 0 for ecoregion Arctic Deserts and Tundra...\n",
      "Processing fold 2 for ecoregion Arctic Deserts and Tundra...\n",
      "Processing fold 4 for ecoregion Arctic Deserts and Tundra...\n",
      "Processing ecoregion Wetlands...\n",
      "Processing fold 0 for ecoregion Wetlands...\n",
      "Processing fold 2 for ecoregion Wetlands...\n",
      "Processing fold 4 for ecoregion Wetlands...\n",
      "Error processing poly_id 1454: Graph execution error:\n",
      "\n",
      "Detected at node 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D' defined at (most recent call last):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 211, in <module>\n",
      "      iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, tif_paths)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 170, in calculate_iou_across_folds_ecoregion\n",
      "      intersection_old, union_old, intersection_ndsi, union_ndsi, intersection_sliding, union_sliding = process_tif_files_for_fold(\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 105, in process_tif_files_for_fold\n",
      "      pred_old = model_1.predict(np.expand_dims(dnbr_old_norm, axis=0), verbose=0)[0].squeeze()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n",
      "      outputs = self.convolution_op(inputs, self.kernel)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n",
      "      return tf.nn.convolution(\n",
      "Node: 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D'\n",
      "CUDNN_STATUS_NOT_SUPPORTED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3594): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\t [[{{node unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D}}]] [Op:__inference_predict_function_2243658]\n",
      "Processing ecoregion Montane Boreal...\n",
      "Processing fold 0 for ecoregion Montane Boreal...\n",
      "Processing fold 2 for ecoregion Montane Boreal...\n",
      "Error processing poly_id 14961: Graph execution error:\n",
      "\n",
      "Detected at node 'unet_model/EfficientNetB7_backbone/stem_conv/Conv2D' defined at (most recent call last):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 211, in <module>\n",
      "      iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, tif_paths)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 170, in calculate_iou_across_folds_ecoregion\n",
      "      intersection_old, union_old, intersection_ndsi, union_ndsi, intersection_sliding, union_sliding = process_tif_files_for_fold(\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 105, in process_tif_files_for_fold\n",
      "      pred_old = model_1.predict(np.expand_dims(dnbr_old_norm, axis=0), verbose=0)[0].squeeze()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n",
      "      outputs = self.convolution_op(inputs, self.kernel)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n",
      "      return tf.nn.convolution(\n",
      "Node: 'unet_model/EfficientNetB7_backbone/stem_conv/Conv2D'\n",
      "CUDNN_STATUS_NOT_SUPPORTED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3594): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\t [[{{node unet_model/EfficientNetB7_backbone/stem_conv/Conv2D}}]] [Op:__inference_predict_function_2810899]\n",
      "Processing fold 4 for ecoregion Montane Boreal...\n",
      "Error processing poly_id 15063: Graph execution error:\n",
      "\n",
      "Detected at node 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D' defined at (most recent call last):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 211, in <module>\n",
      "      iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, tif_paths)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 170, in calculate_iou_across_folds_ecoregion\n",
      "      intersection_old, union_old, intersection_ndsi, union_ndsi, intersection_sliding, union_sliding = process_tif_files_for_fold(\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 105, in process_tif_files_for_fold\n",
      "      pred_old = model_1.predict(np.expand_dims(dnbr_old_norm, axis=0), verbose=0)[0].squeeze()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n",
      "      outputs = self.convolution_op(inputs, self.kernel)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n",
      "      return tf.nn.convolution(\n",
      "Node: 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D'\n",
      "CUDNN_STATUS_NOT_SUPPORTED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3594): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\t [[{{node unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D}}]] [Op:__inference_predict_function_3131702]\n",
      "Processing ecoregion Central Taiga...\n",
      "Processing fold 0 for ecoregion Central Taiga...\n",
      "Processing fold 2 for ecoregion Central Taiga...\n",
      "Processing fold 4 for ecoregion Central Taiga...\n",
      "Error processing poly_id 1454: Graph execution error:\n",
      "\n",
      "Detected at node 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D' defined at (most recent call last):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 211, in <module>\n",
      "      iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, tif_paths)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 170, in calculate_iou_across_folds_ecoregion\n",
      "      intersection_old, union_old, intersection_ndsi, union_ndsi, intersection_sliding, union_sliding = process_tif_files_for_fold(\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 105, in process_tif_files_for_fold\n",
      "      pred_old = model_1.predict(np.expand_dims(dnbr_old_norm, axis=0), verbose=0)[0].squeeze()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n",
      "      outputs = self.convolution_op(inputs, self.kernel)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n",
      "      return tf.nn.convolution(\n",
      "Node: 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D'\n",
      "CUDNN_STATUS_NOT_SUPPORTED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3594): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\t [[{{node unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D}}]] [Op:__inference_predict_function_4073637]\n",
      "Processing ecoregion Northern Taiga...\n",
      "Processing fold 0 for ecoregion Northern Taiga...\n",
      "Processing fold 2 for ecoregion Northern Taiga...\n",
      "Processing fold 4 for ecoregion Northern Taiga...\n",
      "Processing ecoregion Montane Sub-Boreal...\n",
      "Processing fold 0 for ecoregion Montane Sub-Boreal...\n",
      "Processing fold 2 for ecoregion Montane Sub-Boreal...\n",
      "Error processing poly_id 14961: Graph execution error:\n",
      "\n",
      "Detected at node 'unet_model/EfficientNetB7_backbone/stem_conv/Conv2D' defined at (most recent call last):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 211, in <module>\n",
      "      iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, tif_paths)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 170, in calculate_iou_across_folds_ecoregion\n",
      "      intersection_old, union_old, intersection_ndsi, union_ndsi, intersection_sliding, union_sliding = process_tif_files_for_fold(\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 105, in process_tif_files_for_fold\n",
      "      pred_old = model_1.predict(np.expand_dims(dnbr_old_norm, axis=0), verbose=0)[0].squeeze()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n",
      "      outputs = self.convolution_op(inputs, self.kernel)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n",
      "      return tf.nn.convolution(\n",
      "Node: 'unet_model/EfficientNetB7_backbone/stem_conv/Conv2D'\n",
      "CUDNN_STATUS_NOT_SUPPORTED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3594): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\t [[{{node unet_model/EfficientNetB7_backbone/stem_conv/Conv2D}}]] [Op:__inference_predict_function_5392096]\n",
      "Processing fold 4 for ecoregion Montane Sub-Boreal...\n",
      "Error processing poly_id 15063: Graph execution error:\n",
      "\n",
      "Detected at node 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D' defined at (most recent call last):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 211, in <module>\n",
      "      iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, tif_paths)\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 170, in calculate_iou_across_folds_ecoregion\n",
      "      intersection_old, union_old, intersection_ndsi, union_ndsi, intersection_sliding, union_sliding = process_tif_files_for_fold(\n",
      "    File \"/tmp/ipykernel_2500326/1011913464.py\", line 105, in process_tif_files_for_fold\n",
      "      pred_old = model_1.predict(np.expand_dims(dnbr_old_norm, axis=0), verbose=0)[0].squeeze()\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n",
      "      outputs = self.convolution_op(inputs, self.kernel)\n",
      "    File \"/home/spotter5/.conda/envs/deeplearning3/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n",
      "      return tf.nn.convolution(\n",
      "Node: 'unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D'\n",
      "CUDNN_STATUS_NOT_SUPPORTED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3594): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\t [[{{node unet_model/EfficientNetB7_backbone/block2a_expand_conv/Conv2D}}]] [Op:__inference_predict_function_5638211]\n",
      "Processing ecoregion Forest Tundra...\n",
      "Processing fold 0 for ecoregion Forest Tundra...\n",
      "Processing fold 2 for ecoregion Forest Tundra...\n",
      "Processing fold 4 for ecoregion Forest Tundra...\n",
      "Processing ecoregion Southern Taiga...\n",
      "Processing fold 0 for ecoregion Southern Taiga...\n",
      "Processing fold 2 for ecoregion Southern Taiga...\n",
      "Processing fold 4 for ecoregion Southern Taiga...\n",
      "Processing ecoregion Forest Steppe...\n",
      "Processing fold 0 for ecoregion Forest Steppe...\n",
      "Processing fold 2 for ecoregion Forest Steppe...\n",
      "Processing fold 4 for ecoregion Forest Steppe...\n",
      "                   ecoregion   iou_old  iou_ndsi  iou_sliding\n",
      "0         Montane Sub-Arctic  0.688736  0.737434     0.733329\n",
      "1  Arctic Deserts and Tundra  0.640383  0.727783     0.706187\n",
      "2                   Wetlands  0.690918  0.755922     0.741188\n",
      "3             Montane Boreal  0.587533  0.679714     0.648695\n",
      "4              Central Taiga  0.676981  0.762527     0.740087\n",
      "5             Northern Taiga  0.778895  0.826482     0.803843\n",
      "6         Montane Sub-Boreal  0.467356  0.561234     0.496582\n",
      "7              Forest Tundra  0.594448  0.663915     0.651252\n",
      "8             Southern Taiga  0.381096  0.510086     0.468972\n",
      "9              Forest Steppe  0.017496  0.000664     0.012178\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import geopandas as gpd\n",
    "\n",
    "# Function to load models for a specific fold\n",
    "def load_models_for_fold(fold):\n",
    "    model_1 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_{fold}_old.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "    model_2 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "    model_3 = tf.keras.models.load_model(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\", \n",
    "                                         custom_objects={'precision': sm.metrics.Precision(threshold=0.5), \n",
    "                                                         'recall': sm.metrics.Recall(threshold=0.5),\n",
    "                                                         'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                         'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "    return model_1, model_2, model_3\n",
    "\n",
    "# Load min_max dataframe and use columns '6', '7', '8'\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop=True)\n",
    "min_max = min_max[['6', '7', '8']]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(min_max)\n",
    "\n",
    "# Function to normalize the first three bands (6, 7, 8)\n",
    "def norm(img):\n",
    "    img = img[:, :, :3]  # Normalize first three bands\n",
    "    img = img.astype(float)\n",
    "    img[img == 0] = -999\n",
    "    img[np.isnan(img)] = -999\n",
    "    img[img == -999] = np.nan\n",
    "    \n",
    "    in_shape = img.shape\n",
    "    img_flat = img.reshape(-1, img.shape[2])\n",
    "    df_img = pd.DataFrame(img_flat, columns=['6', '7', '8'])\n",
    "    df_img = pd.concat([min_max, df_img]).reset_index(drop=True)\n",
    "    scaled_img = pd.DataFrame(scaler.transform(df_img)).iloc[len(min_max):]\n",
    "    img_scaled = scaled_img.values.reshape(in_shape)\n",
    "    img_scaled[np.isnan(img)] = -1\n",
    "    \n",
    "    return img_scaled\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def calculate_iou(pred, y):\n",
    "    pred_binary = pred > 0.5\n",
    "    y_binary = y > 0.5\n",
    "    intersection = np.logical_and(pred_binary, y_binary).sum()\n",
    "    union = np.logical_or(pred_binary, y_binary).sum()\n",
    "    return intersection, union\n",
    "\n",
    "# Helper function to load and process TIFF files\n",
    "def load_tif(file_path, poly_id):\n",
    "    tif_file = f'median_{poly_id}.tif'\n",
    "    tif_path = os.path.join(file_path, tif_file)\n",
    "    img = rioxarray.open_rasterio(tif_path).to_numpy()\n",
    "    img = np.moveaxis(img, 0, 2)  # Move bands to last axis\n",
    "    return img\n",
    "\n",
    "# Function to crop two arrays to the smallest common shape\n",
    "def crop_to_smallest(pred, y):\n",
    "    min_height = min(pred.shape[0], y.shape[0])\n",
    "    min_width = min(pred.shape[1], y.shape[1])\n",
    "    pred_cropped = pred[:min_height, :min_width]\n",
    "    y_cropped = y[:min_height, :min_width]\n",
    "    return pred_cropped, y_cropped\n",
    "\n",
    "# Main loop to process polygons and accumulate IoU sums\n",
    "def process_tif_files_for_fold(fold, fold_ids, model_1, model_2, model_3, old_path, ndsi_path, sliding_path):\n",
    "    total_intersection_old = 0\n",
    "    total_union_old = 0\n",
    "    total_intersection_ndsi = 0\n",
    "    total_union_ndsi = 0\n",
    "    total_intersection_sliding = 0\n",
    "    total_union_sliding = 0\n",
    "    \n",
    "    for poly_id in fold_ids:\n",
    "        try:\n",
    "            # Load TIFFs for dNBR (band 1) and y (band 4) for each model\n",
    "            y_old = load_tif(old_path, poly_id)[:, :, 3]  # y is band 4\n",
    "            y_ndsi = load_tif(ndsi_path, poly_id)[:, :, 3]\n",
    "            y_sliding = load_tif(sliding_path, poly_id)[:, :, 3]\n",
    "\n",
    "            # Load and normalize images for model predictions\n",
    "            dnbr_old_img = load_tif(old_path, poly_id)\n",
    "            dnbr_ndsi_img = load_tif(ndsi_path, poly_id)\n",
    "            dnbr_sliding_img = load_tif(sliding_path, poly_id)\n",
    "        \n",
    "            dnbr_old_norm = norm(dnbr_old_img)\n",
    "            dnbr_ndsi_norm = norm(dnbr_ndsi_img)\n",
    "            dnbr_sliding_norm = norm(dnbr_sliding_img)\n",
    "        \n",
    "            # Predict using the models\n",
    "            pred_old = model_1.predict(np.expand_dims(dnbr_old_norm, axis=0), verbose=0)[0].squeeze()\n",
    "            pred_ndsi = model_2.predict(np.expand_dims(dnbr_ndsi_norm, axis=0), verbose=0)[0].squeeze()\n",
    "            pred_sliding = model_3.predict(np.expand_dims(dnbr_sliding_norm, axis=0), verbose=0)[0].squeeze()\n",
    "\n",
    "            # Crop predictions and ground truth to smallest common shape\n",
    "            pred_old, y_old = crop_to_smallest(pred_old, y_old)\n",
    "            pred_ndsi, y_ndsi = crop_to_smallest(pred_ndsi, y_ndsi)\n",
    "            pred_sliding, y_sliding = crop_to_smallest(pred_sliding, y_sliding)\n",
    "\n",
    "            # Calculate IoU for each model and accumulate intersection and union\n",
    "            intersection_old, union_old = calculate_iou(pred_old, y_old)\n",
    "            intersection_ndsi, union_ndsi = calculate_iou(pred_ndsi, y_ndsi)\n",
    "            intersection_sliding, union_sliding = calculate_iou(pred_sliding, y_sliding)\n",
    "\n",
    "            # Accumulate for final IoU across all predictions\n",
    "            total_intersection_old += intersection_old\n",
    "            total_union_old += union_old\n",
    "\n",
    "            total_intersection_ndsi += intersection_ndsi\n",
    "            total_union_ndsi += union_ndsi\n",
    "\n",
    "            total_intersection_sliding += intersection_sliding\n",
    "            total_union_sliding += union_sliding\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing poly_id {poly_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return total_intersection_old, total_union_old, total_intersection_ndsi, total_union_ndsi, total_intersection_sliding, total_union_sliding\n",
    "\n",
    "# Main function to calculate IoU for all ecoregions and folds\n",
    "def calculate_iou_across_folds_ecoregion(ecoregions, eco_df, folds, tif_paths):\n",
    "    iou_results = []\n",
    "    \n",
    "    # Loop through each ecoregion\n",
    "    for ecoregion in ecoregions:\n",
    "        print(f\"Processing ecoregion {ecoregion}...\")\n",
    "\n",
    "        total_intersection_old = 0\n",
    "        total_union_old = 0\n",
    "        total_intersection_ndsi = 0\n",
    "        total_union_ndsi = 0\n",
    "        total_intersection_sliding = 0\n",
    "        total_union_sliding = 0\n",
    "        \n",
    "        # Get IDs in this ecoregion\n",
    "        sub_eco = eco_df[eco_df['ecoregion'] == ecoregion]\n",
    "        \n",
    "        for fold in folds:\n",
    "            print(f\"Processing fold {fold} for ecoregion {ecoregion}...\")\n",
    "            \n",
    "            # Load models for the fold\n",
    "            model_1, model_2, model_3 = load_models_for_fold(fold)\n",
    "            \n",
    "            # Load testing data for the fold\n",
    "            testing_names = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')['ID'].tolist()\n",
    "            \n",
    "            # Filter ecoregion and testing names\n",
    "            sub_fold = sub_eco[sub_eco['ID'].isin(testing_names)]\n",
    "            fold_ids = sub_fold['ID'].unique().tolist()\n",
    "            \n",
    "            if len(fold_ids) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Process TIFF files for the current fold\n",
    "            intersection_old, union_old, intersection_ndsi, union_ndsi, intersection_sliding, union_sliding = process_tif_files_for_fold(\n",
    "                fold, fold_ids, model_1, model_2, model_3, tif_paths['old'], tif_paths['ndsi'], tif_paths['sliding'])\n",
    "\n",
    "            # Accumulate results for this fold\n",
    "            total_intersection_old += intersection_old\n",
    "            total_union_old += union_old\n",
    "            total_intersection_ndsi += intersection_ndsi\n",
    "            total_union_ndsi += union_ndsi\n",
    "            total_intersection_sliding += intersection_sliding\n",
    "            total_union_sliding += union_sliding\n",
    "        \n",
    "        # Calculate final IoU for this ecoregion across all folds\n",
    "        iou_old = total_intersection_old / total_union_old if total_union_old != 0 else 0\n",
    "        iou_ndsi = total_intersection_ndsi / total_union_ndsi if total_union_ndsi != 0 else 0\n",
    "        iou_sliding = total_intersection_sliding / total_union_sliding if total_union_sliding != 0 else 0\n",
    "        \n",
    "        # Store the results\n",
    "        iou_results.append({\n",
    "            'ecoregion': ecoregion,\n",
    "            'iou_old': iou_old,\n",
    "            'iou_ndsi': iou_ndsi,\n",
    "            'iou_sliding': iou_sliding\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(iou_results)\n",
    "\n",
    "# List of folds to process\n",
    "folds = [0, 2, 4]  # Adjust the number of folds if necessary\n",
    "\n",
    "# Load ecoregion shapefile\n",
    "eco = gpd.read_file('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_good_eco_clip.shp')\n",
    "all_ecoregions = eco['ecoregion'].unique().tolist()\n",
    "\n",
    "# Define paths for the TIFF files\n",
    "tif_paths = {\n",
    "    'old': '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_old',\n",
    "    'ndsi': '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi',\n",
    "    'sliding': '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding'\n",
    "}\n",
    "\n",
    "# Calculate the IoU across all ecoregions and folds\n",
    "iou_df = calculate_iou_across_folds_ecoregion(all_ecoregions, eco, folds, tif_paths)\n",
    "\n",
    "# Save the results to CSV\n",
    "iou_df.to_csv('/explore/nobackup/people/spotter5/cnn_mapping/Russia/iou_ecoregion_results.csv', index=False)\n",
    "\n",
    "# Print the final IoU values for each ecoregion\n",
    "print(iou_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2dc01-cf26-411f-b898-48e5061124c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning3]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
