{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e5ae20-6c0a-487a-b244-e53381113a65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils.generic_utils' has no attribute 'get_custom_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_unet_collection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Suppress warnings and logs\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/segmentation_models/__init__.py:98\u001b[0m\n\u001b[1;32m     96\u001b[0m _framework \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSM_FRAMEWORK\u001b[39m\u001b[38;5;124m'\u001b[39m, _DEFAULT_KERAS_FRAMEWORK)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mset_framework\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_framework\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     other \u001b[38;5;241m=\u001b[39m _TF_KERAS_FRAMEWORK_NAME \u001b[38;5;28;01mif\u001b[39;00m _framework \u001b[38;5;241m==\u001b[39m _KERAS_FRAMEWORK_NAME \u001b[38;5;28;01melse\u001b[39;00m _KERAS_FRAMEWORK_NAME\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/segmentation_models/__init__.py:68\u001b[0m, in \u001b[0;36mset_framework\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _KERAS_FRAMEWORK_NAME:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m  \u001b[38;5;66;03m# init custom objects\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _TF_KERAS_FRAMEWORK_NAME:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/efficientnet/keras.py:17\u001b[0m\n\u001b[1;32m     13\u001b[0m EfficientNetB7 \u001b[38;5;241m=\u001b[39m inject_keras_modules(model\u001b[38;5;241m.\u001b[39mEfficientNetB7)\n\u001b[1;32m     15\u001b[0m preprocess_input \u001b[38;5;241m=\u001b[39m inject_keras_modules(model\u001b[38;5;241m.\u001b[39mpreprocess_input)\n\u001b[0;32m---> 17\u001b[0m \u001b[43minit_keras_custom_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/efficientnet/__init__.py:71\u001b[0m, in \u001b[0;36minit_keras_custom_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model\n\u001b[1;32m     66\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswish\u001b[39m\u001b[38;5;124m'\u001b[39m: inject_keras_modules(model\u001b[38;5;241m.\u001b[39mget_swish)(),\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedDropout\u001b[39m\u001b[38;5;124m'\u001b[39m: inject_keras_modules(model\u001b[38;5;241m.\u001b[39mget_dropout)()\n\u001b[1;32m     69\u001b[0m }\n\u001b[0;32m---> 71\u001b[0m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_custom_objects\u001b[49m()\u001b[38;5;241m.\u001b[39mupdate(custom_objects)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'get_custom_objects'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Import necessary packages\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "import os\n",
    "import segmentation_models as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import concatenate, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Input, AvgPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_unet_collection import models\n",
    "import geopandas as gpd\n",
    "# import tensorflow_addons as tfa\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the fold number\n",
    "fold = 0\n",
    "\n",
    "# Load min-max normalization values\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop=True)\n",
    "min_max = min_max[['6', '7', '8']]\n",
    "print(min_max)\n",
    "\n",
    "# Function to normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def normalize_meanstd(a, axis=None): \n",
    "    mean = np.mean(a, axis=axis, keepdims=True)\n",
    "    std = np.sqrt(((a - mean)**2).mean(axis=axis, keepdims=True))\n",
    "    return (a - mean) / std\n",
    "\n",
    "# Function to get file paths based on AOI and ID\n",
    "def get_file_paths(df):\n",
    "    file_paths = []\n",
    "    for aoi in df['AOI'].unique():\n",
    "        ids = df[df['AOI'] == aoi]['ID'].tolist()\n",
    "        if aoi == 'anna':\n",
    "            base_dir = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_monthly_ndsi_sliding_subs_0_128/'\n",
    "        elif aoi == 'NBAC':\n",
    "            base_dir = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/nbac_monthly_ndsi_sliding_subs_0_128/'\n",
    "        elif aoi == 'MTBS':\n",
    "            base_dir = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/mtbs_monthly_ndsi_sliding_subs_0_128/'\n",
    "        else:\n",
    "            continue  # Skip unknown AOI\n",
    "\n",
    "        # List all files in the base_dir\n",
    "        all_files = os.listdir(base_dir)\n",
    "\n",
    "        # Filter files whose IDs are in ids\n",
    "        filtered_files = [\n",
    "            os.path.join(base_dir, name) for name in all_files \n",
    "            if int(name.split('_')[-1].split('.')[0]) in ids\n",
    "        ]\n",
    "        file_paths.extend(filtered_files)\n",
    "    return file_paths\n",
    "\n",
    "# Read training, validation, and testing dataframes for each AOI\n",
    "# For Eurasia (anna)\n",
    "training_df_anna = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/train_fold_{fold}.csv')\n",
    "validation_df_anna = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/val_fold_{fold}.csv')\n",
    "testing_df_anna = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/Russia/test_fold_{fold}.csv')\n",
    "\n",
    "training_df_anna['AOI'] = 'anna'\n",
    "validation_df_anna['AOI'] = 'anna'\n",
    "testing_df_anna['AOI'] = 'anna'\n",
    "\n",
    "# For NBAC and MTBS\n",
    "training_df_nbac = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/train_fold_{fold}.csv')\n",
    "validation_df_nbac = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/val_fold_{fold}.csv')\n",
    "testing_df_nbac = pd.read_csv(f'/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/test_fold_{fold}.csv')\n",
    "\n",
    "# Combine dataframes\n",
    "training_df = pd.concat([training_df_anna, training_df_nbac], ignore_index=True)\n",
    "validation_df = pd.concat([validation_df_anna, validation_df_nbac], ignore_index=True)\n",
    "testing_df = pd.concat([testing_df_anna, testing_df_nbac], ignore_index=True)\n",
    "\n",
    "# Create a unique identifier by combining AOI and ID\n",
    "training_df['unique_id'] = training_df['AOI'].astype(str) + '_' + training_df['ID'].astype(str)\n",
    "validation_df['unique_id'] = validation_df['AOI'].astype(str) + '_' + validation_df['ID'].astype(str)\n",
    "testing_df['unique_id'] = testing_df['AOI'].astype(str) + '_' + testing_df['ID'].astype(str)\n",
    "\n",
    "# Ensure there are no duplicates in each set\n",
    "assert not training_df['unique_id'].duplicated().any(), \"Duplicates found in training data.\"\n",
    "assert not validation_df['unique_id'].duplicated().any(), \"Duplicates found in validation data.\"\n",
    "assert not testing_df['unique_id'].duplicated().any(), \"Duplicates found in testing data.\"\n",
    "\n",
    "# Ensure there is no overlap between the sets\n",
    "combined_df = pd.concat([training_df, validation_df, testing_df], ignore_index=True)\n",
    "duplicates = combined_df[combined_df.duplicated(subset=['unique_id'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Overlap found between the datasets:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No overlap found between training, validation, and testing datasets.\")\n",
    "\n",
    "# Get file paths for training, validation, and testing\n",
    "training_names = get_file_paths(training_df)\n",
    "validation_names = get_file_paths(validation_df)\n",
    "testing_names = get_file_paths(testing_df)\n",
    "\n",
    "\n",
    "print(training_names)\n",
    "# # Function to normalize images using min-max scaler\n",
    "# def normalize_image(img):\n",
    "#     img_shape = img.shape\n",
    "#     img = img.reshape(-1, img.shape[2])\n",
    "#     img = pd.DataFrame(img)\n",
    "#     img.columns = min_max.columns\n",
    "#     img = pd.concat([min_max, img]).reset_index(drop=True)\n",
    "#     img = pd.DataFrame(scaler.fit_transform(img))\n",
    "#     img = img.iloc[2:]\n",
    "#     img = img.values.reshape(img_shape)\n",
    "#     img[np.isnan(img)] = -1\n",
    "#     img = np.round(img, 3)\n",
    "#     return img\n",
    "\n",
    "# # Image generator class\n",
    "# class img_gen(tf.keras.utils.Sequence):\n",
    "#     def __init__(self, batch_size, img_size, input_img_paths):\n",
    "#         self.batch_size = batch_size\n",
    "#         self.img_size = img_size\n",
    "#         self.input_img_paths = input_img_paths\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.input_img_paths) // self.batch_size\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         import random\n",
    "#         random.shuffle(self.input_img_paths)\n",
    "#         i = idx * self.batch_size\n",
    "#         batch_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "#         x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "#         y = np.zeros((self.batch_size,) + self.img_size, dtype=\"uint8\")\n",
    "\n",
    "#         for j, path in enumerate(batch_img_paths):\n",
    "#             # Load image\n",
    "#             img = np.round(np.load(path), 3)\n",
    "#             if img.shape[2] == 4:\n",
    "#                 img = img[:, :, :-1]\n",
    "#             else:\n",
    "#                 img = img[:, :, 6:9]\n",
    "#             img = img.astype(float)\n",
    "#             img = np.round(img, 3)\n",
    "#             img[img == 0] = -999\n",
    "#             img[np.isnan(img)] = -999\n",
    "#             img[img == -999] = np.nan\n",
    "\n",
    "#             # Normalize image\n",
    "#             img = normalize_image(img)\n",
    "#             x[j] = img\n",
    "\n",
    "#             # Load mask\n",
    "#             mask = np.round(np.load(path), 3)[:, :, -1]\n",
    "#             mask = mask.astype(int)\n",
    "#             mask[mask < 0] = 0\n",
    "#             mask[mask > 1] = 0\n",
    "#             mask[~np.isin(mask, [0, 1])] = 0\n",
    "#             mask[np.isnan(mask)] = 0\n",
    "#             y[j] = mask.astype(int)\n",
    "\n",
    "#         return x, y\n",
    "\n",
    "# # Initialize GPUs with TensorFlow\n",
    "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices:\n",
    "#     tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# # Set batch size and image size\n",
    "# BATCH_SIZE = 45\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# print('Number of devices: %d' % strategy.num_replicas_in_sync) \n",
    "# batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "# img_size = (128, 128)\n",
    "# num_classes = 1\n",
    "\n",
    "# # Get image generators\n",
    "# train_gen = img_gen(batch_size, img_size, training_names)\n",
    "# val_gen = img_gen(batch_size, img_size, validation_names)\n",
    "# test_gen = img_gen(batch_size, img_size, testing_names)\n",
    "\n",
    "# # Clear any previous models\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# # Define optimizer and loss\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# loss = tf.keras.losses.BinaryFocalCrossentropy(from_logits=False, gamma=2.0, alpha=0.25)\n",
    "\n",
    "# # Define callbacks\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(\n",
    "#         filepath=f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}\",\n",
    "#         save_weights_only=False,\n",
    "#         save_best_only=True,\n",
    "#         monitor='val_unet_output_final_activation_iou_score',\n",
    "#         mode='max'\n",
    "#     ),\n",
    "#     tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_unet_output_final_activation_iou_score', \n",
    "#         mode='max',  \n",
    "#         patience=20\n",
    "#     ),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#         monitor='val_unet_output_final_activation_loss', \n",
    "#         factor=0.5, \n",
    "#         patience=5, \n",
    "#         min_lr=1e-6, \n",
    "#         verbose=1\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# # Open a strategy scope and compile the model\n",
    "# with strategy.scope():\n",
    "#     model_unet_from_scratch = models.unet_plus_2d(\n",
    "#         (None, None, 3), \n",
    "#         filter_num=[16,32,64,128], \n",
    "#         n_labels=num_classes, \n",
    "#         stack_num_down=2, \n",
    "#         stack_num_up=2, \n",
    "#         activation='ReLU', \n",
    "#         output_activation='Sigmoid', \n",
    "#         batch_norm=True, \n",
    "#         pool=False, \n",
    "#         unpool=False, \n",
    "#         backbone='EfficientNetB7', \n",
    "#         weights=None, \n",
    "#         freeze_backbone=False, \n",
    "#         freeze_batch_norm=False, \n",
    "#         deep_supervision=True,\n",
    "#         name='unet'\n",
    "#     )\n",
    "#     model_unet_from_scratch.compile(\n",
    "#         loss='binary_crossentropy',\n",
    "#         optimizer='adam',\n",
    "#         metrics=[\n",
    "#             sm.metrics.Precision(threshold=0.5),\n",
    "#             sm.metrics.Recall(threshold=0.5),\n",
    "#             sm.metrics.FScore(threshold=0.5), \n",
    "#             sm.metrics.IOUScore(threshold=0.5),\n",
    "#             'accuracy'\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# # Fit the model\n",
    "# history = model_unet_from_scratch.fit(\n",
    "#     train_gen,\n",
    "#     epochs=50,\n",
    "#     callbacks=callbacks,\n",
    "#     validation_data=val_gen,\n",
    "#     verbose=0\n",
    "# )\n",
    "\n",
    "# # Save the model\n",
    "# model_unet_from_scratch.save(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/combined_good_ndsi_sliding_{fold}.tf\")\n",
    "\n",
    "# # Save training history\n",
    "# history_dict = history.history\n",
    "# result = pd.DataFrame({\n",
    "#     'Precision': history_dict[\"unet_output_final_activation_precision\"],\n",
    "#     'Val_Precision': history_dict['val_unet_output_final_activation_precision'],\n",
    "#     'Recall': history_dict[\"unet_output_final_activation_recall\"],\n",
    "#     'Val_Recall': history_dict['val_unet_output_final_activation_recall'],\n",
    "#     'F1': history_dict[\"unet_output_final_activation_f1-score\"],\n",
    "#     'Val_F1': history_dict['val_unet_output_final_activation_f1-score'],\n",
    "#     'IOU': history_dict[\"unet_output_final_activation_iou_score\"],\n",
    "#     'Val_IOU': history_dict['val_unet_output_final_activation_iou_score'],\n",
    "#     'Loss': history_dict['unet_output_final_activation_loss'],\n",
    "#     'Val_Loss': history_dict['val_unet_output_final_activation_loss'],\n",
    "#     'Accuracy': history_dict['unet_output_final_activation_accuracy'],\n",
    "#     'Val_Accuracy': history_dict['val_unet_output_final_activation_accuracy']\n",
    "# })\n",
    "# result.to_csv(f\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/combined_good_ndsi_sliding_{fold}.csv\")\n",
    "\n",
    "# # Record the end time and print the time taken\n",
    "# end_time = time.time()\n",
    "# time_difference_seconds = end_time - start_time\n",
    "# time_difference_hours = time_difference_seconds / 3600\n",
    "# print(f\"Time taken: {time_difference_hours:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445845c-afc3-44bb-936c-c5c0483893eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
