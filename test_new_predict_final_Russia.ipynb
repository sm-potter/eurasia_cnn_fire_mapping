{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c81dcb-8720-4d35-8b18-dbe8be9ac98e",
   "metadata": {},
   "source": [
    "This script will take two fires from mtbs and try to use mighty mosaic on them to compare to EE, in hopes it will remove the tiling effect.  MightyMosaic docs: https://github.com/AurelienColin/MightyMosaic#introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b861f7b-b87e-472a-8cf3-2f532cf34bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:41:02.276329: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras import losses\n",
    "import datetime\n",
    "import math,os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import random\n",
    "\n",
    "# from dataProcess import  color_dict\n",
    "\n",
    "#  Read tif data set\n",
    "def readTif(fileName, xoff = 0, yoff = 0, data_width = 0, data_height = 0):\n",
    "    dataset = gdal.Open(fileName)\n",
    "    if dataset == None:\n",
    "        print(fileName + \"file cannot be opened\")\n",
    "    #  Number of columns of raster matrix\n",
    "    width = dataset.RasterXSize\n",
    "    #  Number of rows of raster matrix\n",
    "    height = dataset.RasterYSize\n",
    "    #  Number of columns of raster matrix\n",
    "    bands = dataset.RasterCount\n",
    "    #  retrieve data\n",
    "    if(data_width == 0 and data_height == 0):\n",
    "        data_width = width\n",
    "        data_height = height\n",
    "    data = dataset.ReadAsArray(xoff, yoff, data_width, data_height)\n",
    "    # Get affine matrix information\n",
    "    geotrans = dataset.GetGeoTransform()\n",
    "    # get projection info\n",
    "    proj = dataset.GetProjection()\n",
    "    return width, height, bands, data, geotrans, proj\n",
    "\n",
    "#save tif file function\n",
    "def writeTiff(im_data, im_geotrans, im_proj, path):\n",
    "    if 'int8' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_Byte\n",
    "    elif 'int16' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt16\n",
    "    else:\n",
    "        datatype = gdal.GDT_Float32\n",
    "    if len(im_data.shape) == 3:\n",
    "        im_bands, im_height, im_width = im_data.shape\n",
    "    elif len(im_data.shape) == 2:\n",
    "        im_data = np.array([im_data])\n",
    "        im_bands, im_height, im_width = im_data.shape\n",
    "\n",
    "    #create a fiile\n",
    "    path_compress=path\n",
    "    path=path.replace('.tif','orig.tif')\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dataset = driver.Create(path, int(im_width), int(im_height), int(im_bands), datatype)\n",
    "    if(dataset!= None):\n",
    "        dataset.SetGeoTransform(im_geotrans) #Write affine transformation parameters\n",
    "        dataset.SetProjection(im_proj) #write projection\n",
    "    for i in range(im_bands):\n",
    "        dataset.GetRasterBand(i+1).WriteArray(im_data[i])\n",
    "    del dataset\n",
    "    compress(path,path_compress)\n",
    "\n",
    "def compress(path, target_path,method=\"LZW\"): #\n",
    "    \"\"\"Using gdal for file compression,\n",
    "          The LZW method is lossless compression and has better black and white image effects.\n",
    "          \"\"\"\n",
    "    dataset = gdal.Open(path)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    driver.CreateCopy(target_path, dataset, strict=1, options=[\"TILED=YES\", \"COMPRESS={0}\".format(method)])\n",
    "    del dataset\n",
    "    os.remove(path)\n",
    "    \n",
    "\n",
    "#  tif crop (tif pixel data, crop side length)\n",
    "def TifCroppingArray(img, SideLength):\n",
    "    #  Cut the linked list\n",
    "    TifArrayReturn = []\n",
    "    #  Number of image blocks on the column\n",
    "    ColumnNum = int((img.shape[0] - SideLength * 2) / (128 - SideLength * 2))\n",
    "    #  Number of image blocks on the line\n",
    "    RowNum = int((img.shape[1] - SideLength * 2) / (128 - SideLength * 2))\n",
    "    for i in range(ColumnNum):\n",
    "        TifArray = []\n",
    "        for j in range(RowNum):\n",
    "            cropped = img[i * (128 - SideLength * 2) : i * (128 - SideLength * 2) + 128,\n",
    "                          j * (128 - SideLength * 2) : j * (128 - SideLength * 2) + 128]\n",
    "            TifArray.append(cropped)\n",
    "        TifArrayReturn.append(TifArray)\n",
    "    #  Considering that there will be remainders in the rows and columns, crop one row and one column forward.\n",
    "    #  Crop last column forward\n",
    "    for i in range(ColumnNum):\n",
    "        cropped = img[i * (128 - SideLength * 2) : i * (128 - SideLength * 2) + 128,\n",
    "                      (img.shape[1] - 128) : img.shape[1]]\n",
    "        TifArrayReturn[i].append(cropped)\n",
    "    #  Crop last row forward\n",
    "    TifArray = []\n",
    "    for j in range(RowNum):\n",
    "        cropped = img[(img.shape[0] - 128) : img.shape[0],\n",
    "                      j * (128-SideLength*2) : j * (128 - SideLength * 2) + 128]\n",
    "        TifArray.append(cropped)\n",
    "    #  Crop lower right corner forward\n",
    "    cropped = img[(img.shape[0] - 128) : img.shape[0],\n",
    "                  (img.shape[1] - 128) : img.shape[1]]\n",
    "    TifArray.append(cropped)\n",
    "    TifArrayReturn.append(TifArray)\n",
    "    #  remaining number on column\n",
    "    ColumnOver = (img.shape[0] - SideLength * 2) % (128 - SideLength * 2) + SideLength\n",
    "    #  remaining number on the line\n",
    "    RowOver = (img.shape[1] - SideLength * 2) % (128 - SideLength * 2) + SideLength\n",
    "    return TifArrayReturn, RowOver, ColumnOver\n",
    "\n",
    "#  Label visualization, that is, assigning n values to the nth category\n",
    "def labelVisualize(img):\n",
    "    img_out = np.zeros((img.shape[0],img.shape[1]))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            #  Assign n value to nth class\n",
    "            img_out[i][j] = np.argmax(img[i][j])\n",
    "    return img_out\n",
    "\n",
    "#  Normalize the test image and make its dimensions consistent with the training image\n",
    "def testGenerator(TifArray):\n",
    "\n",
    "    for i in range(len(TifArray)):\n",
    "        for j in range(len(TifArray[0])):\n",
    "            img = TifArray[i][j]\n",
    "            \n",
    "            # img = img[:, :, :-1] #don't have labels\n",
    "            #normalize\n",
    "            # img = img / 255.0\n",
    "            #reshape\n",
    "            # img = np.reshape(img,(1,)+img.shape)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            yield img\n",
    "            \n",
    "# Create a generator function\n",
    "def generator(tif_files):\n",
    "    for tif_file in tif_files:\n",
    "        # img = load_and_preprocess_image(tif_file)  # Implement a function to load and preprocess your image\n",
    "        img = np.expand_dims(tif_file, axis=0)  # Add batch dimension\n",
    "        yield img\n",
    "\n",
    "\n",
    "#  Get the result matrix\n",
    "def Result(shape, TifArray, npyfile, num_class, RepetitiveLength, RowOver, ColumnOver):\n",
    "    result = np.zeros(shape, np.float32)\n",
    "    #  j to mark the number of rows\n",
    "    j = 0\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = item[:, :, 0]\n",
    "      \n",
    "        #  Special consideration is given to the leftmost column. The left edge must be spliced ​​in.\n",
    "        if(i % len(TifArray[0]) == 0):\n",
    "            #  The first row needs special consideration, and the upper edge needs to be taken into account.\n",
    "            if(j == 0):\n",
    "                result[0 : 128 - RepetitiveLength, 0 : 128-RepetitiveLength] = img[0 : 128 - RepetitiveLength, 0 : 128 - RepetitiveLength]\n",
    "            #  The last line needs special consideration, and the lower edge needs to be taken into account.\n",
    "            elif(j == len(TifArray) - 1):\n",
    "                #  It turned out to be wrong\n",
    "                #result[shape[0] - ColumnOver : shape[0], 0 : 128 - RepetitiveLength] = img[0 : ColumnOver, 0 : 128 - RepetitiveLength]\n",
    "                #  Modified later\n",
    "                result[shape[0] - ColumnOver - RepetitiveLength: shape[0], 0 : 128 - RepetitiveLength] = img[128 - ColumnOver - RepetitiveLength : 128, 0 : 128 - RepetitiveLength]\n",
    "            else:\n",
    "                result[j * (128 - 2 * RepetitiveLength) + RepetitiveLength : (j + 1) * (128 - 2 * RepetitiveLength) + RepetitiveLength,\n",
    "                       0:128-RepetitiveLength] = img[RepetitiveLength : 128 - RepetitiveLength, 0 : 128 - RepetitiveLength]\n",
    "        #  Special consideration is given to the rightmost column, the right edge should be spliced ​​in\n",
    "        elif(i % len(TifArray[0]) == len(TifArray[0]) - 1):\n",
    "            #  The first row needs special consideration, and the upper edge needs to be taken into account.\n",
    "            if(j == 0):\n",
    "                result[0 : 128 - RepetitiveLength, shape[1] - RowOver: shape[1]] = img[0 : 128 - RepetitiveLength, 128 -  RowOver: 128]\n",
    "            #  The last line needs special consideration, and the lower edge needs to be taken into account.\n",
    "            elif(j == len(TifArray) - 1):\n",
    "                result[shape[0] - ColumnOver : shape[0], shape[1] - RowOver : shape[1]] = img[128 - ColumnOver : 128, 128 - RowOver : 128]\n",
    "            else:\n",
    "                result[j * (128 - 2 * RepetitiveLength) + RepetitiveLength : (j + 1) * (128 - 2 * RepetitiveLength) + RepetitiveLength,\n",
    "                       shape[1] - RowOver : shape[1]] = img[RepetitiveLength : 128 - RepetitiveLength, 128 - RowOver : 128]\n",
    "            #  After walking to the far right of each row, the number of rows +1\n",
    "            j = j + 1\n",
    "        #  Neither the far left nor the far right\n",
    "        else:\n",
    "            #  Special consideration should be given to the first row, and the upper edge should be taken into account.\n",
    "            if(j == 0):\n",
    "                result[0 : 128 - RepetitiveLength,\n",
    "                       (i - j * len(TifArray[0])) * (128 - 2 * RepetitiveLength) + RepetitiveLength : (i - j * len(TifArray[0]) + 1) * (128 - 2 * RepetitiveLength) + RepetitiveLength\n",
    "                       ] = img[0 : 128 - RepetitiveLength, RepetitiveLength : 128 - RepetitiveLength]\n",
    "            #  Special consideration should be given to the last line, and the lower edge should be taken into account.\n",
    "            if(j == len(TifArray) - 1):\n",
    "                result[shape[0] - ColumnOver : shape[0],\n",
    "                       (i - j * len(TifArray[0])) * (128 - 2 * RepetitiveLength) + RepetitiveLength : (i - j * len(TifArray[0]) + 1) * (128 - 2 * RepetitiveLength) + RepetitiveLength\n",
    "                       ] = img[128 - ColumnOver : 128, RepetitiveLength : 128 - RepetitiveLength]\n",
    "            else:\n",
    "                result[j * (128 - 2 * RepetitiveLength) + RepetitiveLength : (j + 1) * (128 - 2 * RepetitiveLength) + RepetitiveLength,\n",
    "                       (i - j * len(TifArray[0])) * (128 - 2 * RepetitiveLength) + RepetitiveLength : (i - j * len(TifArray[0]) + 1) * (128 - 2 * RepetitiveLength) + RepetitiveLength,\n",
    "                       ] = img[RepetitiveLength : 128 - RepetitiveLength, RepetitiveLength : 128 - RepetitiveLength]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eaecd6d-4530-46e4-9fd1-64276fb8941e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:41:29.251764: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-02-26 12:41:29.251825: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-26 12:41:29.251854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (prismcompute201): /proc/driver/nvidia/version does not exist\n",
      "2024-02-26 12:41:29.252194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model input shape is (None, 128, 128, 3)\n",
      "The model input shape is (None, None, None, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "\n",
    "model = tf.keras.models.load_model(\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/nbac_mtbs_shaped.tf\", \n",
    "                                           custom_objects={'precision':sm.metrics.Precision(threshold=0.5), \n",
    "                                                           'recall':sm.metrics.Recall(threshold = 0.5),\n",
    "                                                            'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                             'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "model2 = tf.keras.models.load_model(\"/explore/nobackup/people/spotter5/cnn_mapping/Russia/models/nbac_mtbs.tf\", \n",
    "                                           custom_objects={'precision':sm.metrics.Precision(threshold=0.5), \n",
    "                                                           'recall':sm.metrics.Recall(threshold = 0.5),\n",
    "                                                            'f1-score': sm.metrics.FScore(threshold=0.5),\n",
    "                                                             'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "print(f\"The model input shape is {model.input_shape}\")\n",
    "print(f\"The model input shape is {model2.input_shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8939e-e2c8-4176-a41a-91fae5a18cf7",
   "metadata": {},
   "source": [
    "Function to do my normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e963da-3bb4-4c61-b5cc-dfae06bb144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_norm(img):\n",
    "    \n",
    "\n",
    "    #convert to band last\n",
    "    im_data = np.moveaxis(img, 0, 2)[:, :, :-1] \n",
    "\n",
    "    #  Normalized\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop = True)\n",
    "\n",
    "    min_max = min_max[['6', '7', '8']]\n",
    "\n",
    "    # im_data =  np.round(im_data, 3)[:, :, 6:9]\n",
    "\n",
    "    # img = img * 1000\n",
    "    im_data = im_data.astype(float)\n",
    "    im_data = np.round(im_data, 3)\n",
    "    im_data[im_data == 0] = -999\n",
    "\n",
    "    im_data[np.isnan(im_data)] = -999\n",
    "\n",
    "\n",
    "    im_data[im_data == -999] = np.nan\n",
    "\n",
    "    in_shape = im_data.shape\n",
    "\n",
    "    #turn to dataframe to normalize\n",
    "    im_data = im_data.reshape(im_data.shape[0] * im_data.shape[1], im_data.shape[2])\n",
    "\n",
    "    im_data = pd.DataFrame(im_data)\n",
    "\n",
    "    im_data.columns = min_max.columns\n",
    "\n",
    "    im_data = pd.concat([min_max, im_data]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "    #normalize 0 to 1\n",
    "    im_data = pd.DataFrame(scaler.fit_transform(im_data))\n",
    "\n",
    "    im_data = im_data.iloc[2:]\n",
    "    #\n",
    "    #             img = img.values.reshape(in_shape)\n",
    "    im_data = im_data.values.reshape(in_shape)\n",
    "\n",
    "    #             replace nan with -1\n",
    "    im_data[np.isnan(im_data)] = -1\n",
    "    \n",
    "    return im_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433366c0-7e22-4e82-b9a0-5c9ea11edea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(555)\n",
    "\n",
    "#Overlap area parameter\n",
    "area_perc = 0.99\n",
    "#  Count background class\n",
    "classNum=1\n",
    "\n",
    "#  test data path\n",
    "TifPath = glob.glob('/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_training_85/*.tif')\n",
    "\n",
    "TifPath = random.choice(TifPath)\n",
    "\n",
    "TifPath = '/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_training_85/median_15851.tif'\n",
    "\n",
    "y =  rioxarray.open_rasterio(TifPath).to_numpy()[-1, :, :]\n",
    "\n",
    "#potentila checks\n",
    "'''\n",
    "/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_training_85/median_7625.tif\n",
    "/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_training_85/median_12846.tif\n",
    "'/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_training_85/median_2547.tif\n",
    "'''\n",
    "#  Results save path\n",
    "ResultPath = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/Russia/test_pred'\n",
    "os.makedirs(ResultPath, exist_ok = True)\n",
    "\n",
    "# train_label_path=\"./dataset/train/label\"\n",
    "\n",
    "RepetitiveLength = int((1 - math.sqrt(area_perc)) * 128 / 2)\n",
    "RepetitiveLength  = 50\n",
    "\n",
    "# files=os.listdir(TifPath)\n",
    "# for i,file in enumerate(files):\n",
    "im_width, im_height, im_bands, im_data, im_geotrans, im_proj = readTif(TifPath)\n",
    "\n",
    "im_data= my_norm(im_data)\n",
    "\n",
    "\n",
    "TifArray, RowOver, ColumnOver = TifCroppingArray(im_data, RepetitiveLength) #TifArray is where 25 is coming from, it is 5x5.  25 sub images in this case\n",
    "\n",
    "flat_list = [\n",
    "    x\n",
    "    for xs in TifArray\n",
    "    for x in xs\n",
    "]\n",
    "\n",
    "# testGene = testGenerator(flat_list) #make generator, used to be TifArray if not flat\n",
    "# results = model.predict_generator(testGene,\n",
    "#                                   len(TifArray) * len(TifArray[0]),\n",
    "#                                   verbose = 0)\n",
    "\n",
    "testGene = generator(flat_list) #make generator, used to be TifArray if not flat\n",
    "testGene2 = generator(flat_list) #make generator, used to be TifArray if not flat\n",
    "\n",
    "#-----for shaped data\n",
    "results = np.array(model.predict_generator(testGene,\n",
    "                                  len(flat_list),\n",
    "                                  verbose = 0))[0, :, :, :, :]\n",
    "# #Save results\n",
    "result_shape = (im_data.shape[0], im_data.shape[1])\n",
    "result_data = Result(result_shape, TifArray, results, 2, RepetitiveLength, RowOver, ColumnOver)\n",
    "\n",
    "thresholded = result_data.copy()\n",
    "thresholded[thresholded <0.5] = np.nan\n",
    "thresholded[np.isnan(thresholded) == False] = 1\n",
    "\n",
    "\n",
    "#---------for not shaped data\n",
    "results2 = np.array(model2.predict_generator(testGene2,\n",
    "                                  len(flat_list),\n",
    "                                  verbose = 0))[0, :, :, :, :]\n",
    "# #Save results\n",
    "result_shape2 = (im_data.shape[0], im_data.shape[1])\n",
    "result_data2 = Result(result_shape2, TifArray, results2, 2, RepetitiveLength, RowOver, ColumnOver)\n",
    "\n",
    "thresholded2 = result_data2.copy()\n",
    "thresholded2[thresholded2 <0.5] = np.nan\n",
    "thresholded2[np.isnan(thresholded2) == False] = 1\n",
    "\n",
    "dnbr = im_data[:, :, 0]\n",
    "\n",
    "# Create a 2x2 subplot\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 11))\n",
    "\n",
    "# Plot y\n",
    "axs[0, 0].imshow(y)\n",
    "axs[0, 0].set_title('Reference Fire')\n",
    "\n",
    "# Plot dnbr\n",
    "axs[0, 1].imshow(dnbr, vmin = 0, vmax =  0.6, cmap = 'RdYlBu_r')\n",
    "axs[0, 1].set_title('dnbr')\n",
    "\n",
    "# Plot result_data\n",
    "axs[1, 0].imshow(result_data, cmap='viridis')\n",
    "axs[1, 0].set_title('Predicted Shaped (128, 128, 3)')\n",
    "\n",
    "# Plot thresholded\n",
    "axs[1, 1].imshow(thresholded, cmap='viridis')\n",
    "axs[1, 1].set_title('Predicted Shaped Thresholded')\n",
    "\n",
    "# Plot result_data\n",
    "axs[2, 0].imshow(result_data2, cmap='viridis')\n",
    "axs[2, 0].set_title('Predicted Not Shaped (None, None, 3)')\n",
    "\n",
    "# Plot thresholded\n",
    "axs[2, 1].imshow(thresholded2, cmap='viridis')\n",
    "axs[2, 1].set_title('Predicted Not Shaped Thresholded')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# fig.savefig('/explore/nobackup/people/spotter5/cnn_mapping/Russia/tiling_example2.png')  # Save the figure to the specified path\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(TifPath)\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0667bd-951b-4b27-8754-2ae6c621cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14115790-204d-4d5a-a470-b07219a0965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/cnn_mapping/Russia/anna_training_85/median_7095.tif\n"
     ]
    }
   ],
   "source": [
    "print(TifPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd06198-19ab-47d7-9ed3-18740936dc49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning3]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
