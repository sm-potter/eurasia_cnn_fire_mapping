{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ce429d-af33-40fd-8638-e62ffa201576",
   "metadata": {},
   "source": [
    "Read in all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5183878f-0f72-42ec-84f0-8fda2b884ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import numpy as np\n",
    "from geeml.extract import extractor\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# import geemap\n",
    "# Authenticate GEE\n",
    "# ee.Authenticate()\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "\n",
    "service_account = 'gee-serdp-upload@appspot.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "ee.Initialize(credentials)\n",
    "# Initialize GEE with high-volume end-point\n",
    "# ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19813541-9f8c-4105-9a4b-e1fbf218ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "from google.cloud import storage\n",
    "from google.cloud import client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7079fbd-131b-4590-a7c0-95b1b658bc75",
   "metadata": {},
   "source": [
    "Read in assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112d5a6a-b286-4cc1-8e72-242e93a52be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent_2A = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") #sentinel 2\n",
    "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY') #cloud masking for sentinel\n",
    "lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ea_grid\") \n",
    "\n",
    "#need to add ids to annas polygons\n",
    "# Create a sequence of numbers from 1 to the number of features\n",
    "# indexes = lfdb.aggregate_array('system:index')\n",
    "# ids = list(range(1, indexes.size().getInfo() + 1))\n",
    "# idByIndex = ee.Dictionary.fromLists(indexes, ids)\n",
    "\n",
    "# # Map over the collection and set the 'ID' property\n",
    "# lfdb = lfdb.map(lambda feature: feature.set('ID', idByIndex.get(feature.get('system:index'))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88507678-1d1d-4e8a-b35f-04dc676ddda9",
   "metadata": {},
   "source": [
    "Mask clouds Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5ec6b5-f3ea-416d-ab22-25ec553a89d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#probability of clouds\n",
    "MAX_CLOUD_PROBABILITY = 50\n",
    "\n",
    "def sent_maskcloud(image):\n",
    "    \n",
    "    \n",
    "    image = image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'])# rename bands to match landsat\n",
    "  \n",
    "    image =  image.toShort()\n",
    "    \n",
    "    clouds = ee.Image(image.get('cloud_mask')).select('probability')\n",
    "    \n",
    "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
    "    \n",
    "    image = image.updateMask(isNotCloud)\n",
    "\n",
    "    #reproject 30m but remember b1, b2 and b3 are 10 and the rest are 20\n",
    "    image1 = image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4'])\n",
    "    image2 = image.select(['SR_B5', 'SR_B7'])\n",
    "\n",
    "    \n",
    "    image1 = image1.reproject(\n",
    "    crs = image1.projection().crs(),\n",
    "    scale = 30) #resample for landsat\n",
    "    \n",
    "    \n",
    "    image2 = image2.reproject(\n",
    "    crs = image2.projection().crs(),\n",
    "    scale = 30) #resample for landsat\n",
    "    \n",
    "    image = image1.addBands(image2)\n",
    "    \n",
    "    return image \n",
    "\n",
    "#Join S2 SR with cloud probability dataset to add cloud mask.\n",
    "s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
    "    \n",
    "  primary=sent_2A,\n",
    "  secondary=s2Clouds,\n",
    "  condition=ee.Filter.equals(leftField='system:index', rightField='system:index'))\n",
    "\n",
    "#apply cloud masking\n",
    "sent_2A = ee.ImageCollection(s2SrWithCloudMask).map(sent_maskcloud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863fb50-782b-4b7a-b25a-94d3d51ca032",
   "metadata": {},
   "source": [
    "Mask clouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35acd43f-65a9-46cf-9200-ef3591158bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_s2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0) \\\n",
    "        .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "\n",
    "    return image.updateMask(mask).divide(10000) #dividing is the scale factor application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c4ebf-0107-43e7-b251-5ec6ebeb58f2",
   "metadata": {},
   "source": [
    "Coefficients from Logan Berner to apply correction factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793967d-7d8a-4816-b08a-e5802713a298",
   "metadata": {},
   "source": [
    "Authenticate my google bucket, not sure if this is needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cf79c3-321c-4b93-8e1e-d019ea137db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "storage_client = storage.Client.from_service_account_json(\"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "storage_client = storage.Client()\n",
    "# bucket_name = 'smp-scratch/mtbs_1985'\n",
    "bucket_name = 'smp-scratch'\n",
    "\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e37cae-c880-4a4f-a988-c304f5a1f9b9",
   "metadata": {},
   "source": [
    "There are going to be issues later with different band types, so cast them all to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b823b48d-3592-44ba-a643-a12f2c54326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_float(image):\n",
    "\n",
    "    b1 = image.select('SR_B1').cast({'SR_B1':'float'}) #0\n",
    "    b2 = image.select('SR_B2').cast({'SR_B2':'float'}) #1\n",
    "    b3 = image.select('SR_B3').cast({'SR_B3':'float'}) #2\n",
    "    b4 = image.select('SR_B4').cast({'SR_B4':'float'}) #3\n",
    "    b5 = image.select('SR_B5').cast({'SR_B5':'float'}) #4\n",
    "    b6 = image.select('SR_B7').cast({'SR_B7':'float'}) #5\n",
    "\n",
    "    image = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af2abd-6347-49ce-b282-72acb64aef30",
   "metadata": {},
   "source": [
    "Function to get the HLS post fire data for a specific time frame.  ONly need to specify post fire dates here.  I will download a variety using different months to test.  Note HLS is only 2017-present.  It seems really only 2019 though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76e6fbf-f2ea-4e67-9c4f-e5118f43c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagery(start, end, geometry):\n",
    "    \n",
    "    #hls image collection, filter date, geometry, cloud masking, take median\n",
    "    hls = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterDate(start, end).filterBounds(geometry).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20)).map(mask_s2clouds).median()\n",
    "    \n",
    "    #resample blue green red to 20m\n",
    "    bgr = hls.select(['B2', 'B3', 'B4'])\n",
    "    \n",
    "    #select nir, swir1, swir2, already at 20m\n",
    "    ns = hls.select(['B8', 'B11', 'B12'])\n",
    "    \n",
    "    bgr= bgr.reproject(\n",
    "        crs = bgr.projection().crs(),\n",
    "        scale = 20) \n",
    "    \n",
    "    \n",
    "    image = bgr.addBands(ns)\n",
    "    \n",
    "    #return the image\n",
    "    return image\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e9e80a9-0974-4a2e-a6ad-24f0084560cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2020_04_01_05_01_hls_186.tif\n",
      "Downloading 2020_05_01_06_01_hls_186.tif\n",
      "Downloading 2020_06_01_07_01_hls_186.tif\n",
      "Downloading 2020_07_01_08_01_hls_186.tif\n",
      "Downloading 2020_08_01_09_01_hls_186.tif\n",
      "Downloading 2020_09_01_10_01_hls_186.tif\n",
      "Downloading 2020_04_01_05_01_hls_131.tif\n",
      "Downloading 2020_05_01_06_01_hls_131.tif\n",
      "Downloading 2020_06_01_07_01_hls_131.tif\n",
      "Downloading 2020_07_01_08_01_hls_131.tif\n",
      "Downloading 2020_08_01_09_01_hls_131.tif\n",
      "Downloading 2020_09_01_10_01_hls_131.tif\n",
      "Downloading 2020_04_01_05_01_hls_175.tif\n",
      "Downloading 2020_05_01_06_01_hls_175.tif\n",
      "Downloading 2020_06_01_07_01_hls_175.tif\n",
      "Downloading 2020_07_01_08_01_hls_175.tif\n",
      "Downloading 2020_08_01_09_01_hls_175.tif\n",
      "Downloading 2020_09_01_10_01_hls_175.tif\n",
      "Downloading 2020_04_01_05_01_hls_189.tif\n",
      "Downloading 2020_05_01_06_01_hls_189.tif\n",
      "Downloading 2020_06_01_07_01_hls_189.tif\n",
      "Downloading 2020_07_01_08_01_hls_189.tif\n",
      "Downloading 2020_08_01_09_01_hls_189.tif\n",
      "Downloading 2020_09_01_10_01_hls_189.tif\n",
      "Downloading 2020_04_01_05_01_hls_72.tif\n",
      "Downloading 2020_05_01_06_01_hls_72.tif\n",
      "Downloading 2020_06_01_07_01_hls_72.tif\n",
      "Downloading 2020_07_01_08_01_hls_72.tif\n",
      "Downloading 2020_08_01_09_01_hls_72.tif\n",
      "Downloading 2020_09_01_10_01_hls_72.tif\n",
      "Downloading 2020_04_01_05_01_hls_163.tif\n",
      "Downloading 2020_05_01_06_01_hls_163.tif\n",
      "Downloading 2020_06_01_07_01_hls_163.tif\n",
      "Downloading 2020_07_01_08_01_hls_163.tif\n",
      "Downloading 2020_08_01_09_01_hls_163.tif\n",
      "Downloading 2020_09_01_10_01_hls_163.tif\n"
     ]
    }
   ],
   "source": [
    "pre_months = ['-04-01', '-05-01', '-06-01', '-07-01', '-08-01', '-09-01']\n",
    "end_months = ['-05-01', '-06-01', '-07-01', '-08-01', '-09-01', '-10-01']\n",
    "\n",
    "all_months = dict(zip(pre_months, end_months))\n",
    "\n",
    "#these ids have a mix of grassland (early season) and siberia (late season) burns.\n",
    "all_ids = [186, 131, 175, 189, 72, 163]\n",
    "#loop through each fire polygon\n",
    "\n",
    "year = 2020\n",
    "\n",
    "for i in all_ids:\n",
    "    \n",
    "    sub_shape = lfdb.filter(ee.Filter.eq('Id', i))\n",
    "        \n",
    "        \n",
    "     #loop through all months \n",
    "    for m1, m2 in all_months.items():\n",
    "        \n",
    "        m1_name = m1.replace('-', '_')\n",
    "        m2_name = m2.replace('-', '_')\n",
    "        #name of output file\n",
    "        fname = f\"{year}{m1_name}{m2_name}_hls_{i}.tif\"\n",
    "\n",
    "        #check if file exists on my bucket, if it does skip\n",
    "        stats = storage.Blob(bucket=bucket, name=fname).exists(storage_client)\n",
    "\n",
    "        if stats == False:\n",
    "\n",
    "            #get imagary dates\n",
    "\n",
    "            start = str(year) + m1\n",
    "            end = str(year) + m2\n",
    "\n",
    "\n",
    "\n",
    "            #apply the function to get the pre_fire image and post_fire image\n",
    "            this_image =  get_imagery(start, end, sub_shape)\n",
    "            \n",
    "\n",
    "            #start download\n",
    "            print(f\"Downloading {fname}\")\n",
    "\n",
    "\n",
    "            #export image to my cloud storage\n",
    "            task = ee.batch.Export.image.toCloudStorage(\n",
    "                                    image = this_image.multiply(1000).toShort(),\n",
    "                                    region=sub_shape.geometry(), \n",
    "                                    description=fname,\n",
    "                                    scale=20,\n",
    "                                    crs='EPSG:3413',\n",
    "                                    maxPixels=1e13,\n",
    "                                    bucket = 'smp-scratch')\n",
    "\n",
    "            task.start()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "430d2bf1-8dda-4786-af84-d2b07ff37882",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_bands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use reduceRegion to calculate the minimum and maximum values in the specified ROI\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mraw_bands\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNBR_p85\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreduceRegion(\n\u001b[1;32m      3\u001b[0m     reducer\u001b[38;5;241m=\u001b[39mee\u001b[38;5;241m.\u001b[39mReducer\u001b[38;5;241m.\u001b[39mminMax(),\n\u001b[1;32m      4\u001b[0m     geometry\u001b[38;5;241m=\u001b[39mfinal_buffer,\n\u001b[1;32m      5\u001b[0m     scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,  \u001b[38;5;66;03m# Set the scale according to the resolution of the image\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     maxPixels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e9\u001b[39m  \u001b[38;5;66;03m# Adjust maxPixels as needed\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get the minimum and maximum values\u001b[39;00m\n\u001b[1;32m     10\u001b[0m min_value \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mgetNumber(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNBR_p85_min\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_bands' is not defined"
     ]
    }
   ],
   "source": [
    "# Use reduceRegion to calculate the minimum and maximum values in the specified ROI\n",
    "stats = raw_bands.select('NBR_p85').reduceRegion(\n",
    "    reducer=ee.Reducer.minMax(),\n",
    "    geometry=final_buffer,\n",
    "    scale=30,  # Set the scale according to the resolution of the image\n",
    "    maxPixels=1e9  # Adjust maxPixels as needed\n",
    ")\n",
    "\n",
    "# Get the minimum and maximum values\n",
    "min_value = stats.getNumber('NBR_p85_min')\n",
    "max_value = stats.getNumber('NBR_p85_max')\n",
    "\n",
    "# Print the results\n",
    "print('Minimum Value:', min_value.getInfo())\n",
    "print('Maximum Value:', max_value.getInfo())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gee_ml]",
   "language": "python",
   "name": "conda-env-.conda-gee_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
